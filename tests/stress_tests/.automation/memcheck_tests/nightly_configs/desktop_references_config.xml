<?xml version="1.0"?>
<attributes>
    <models>
        # Values from "commit_id": "00c1f3bccea9e07cdc37dc33bb009b3481e3faa4"
        <model path="intel/age-gender-recognition-retail-0013/FP16-INT8/age-gender-recognition-retail-0013.xml" precision="FP16-INT8" test="create_exenetwork" device="CPU" vmsize="932770" vmpeak="1004021" vmrss="51963" vmhwm="51963" />
        <model path="intel/age-gender-recognition-retail-0013/FP16-INT8/age-gender-recognition-retail-0013.xml" precision="FP16-INT8" test="create_exenetwork" device="GPU" vmsize="2316605" vmpeak="2396050" vmrss="290794" vmhwm="465400" />
        <model path="intel/age-gender-recognition-retail-0013/FP16-INT8/age-gender-recognition-retail-0013.xml" precision="FP16-INT8" test="infer_request_inference" device="CPU" vmsize="932770" vmpeak="932770" vmrss="57267" vmhwm="57267" />
        <model path="intel/age-gender-recognition-retail-0013/FP16-INT8/age-gender-recognition-retail-0013.xml" precision="FP16-INT8" test="infer_request_inference" device="GPU" vmsize="2316605" vmpeak="2396050" vmrss="294065" vmhwm="464874" />
        <model path="intel/age-gender-recognition-retail-0013/FP16-INT8/age-gender-recognition-retail-0013.xml" precision="FP16-INT8" test="inference_with_streams" device="CPU" vmsize="941886" vmpeak="1027083" vmrss="62004" vmhwm="62004" />
        <model path="intel/age-gender-recognition-retail-0013/FP16-INT8/age-gender-recognition-retail-0013.xml" precision="FP16-INT8" test="inference_with_streams" device="GPU" vmsize="2407137" vmpeak="2486666" vmrss="315978" vmhwm="465036" />
        <model path="intel/face-detection-adas-0001/FP16-INT8/face-detection-adas-0001.xml" precision="FP16-INT8" test="create_exenetwork" device="CPU" vmsize="1009184" vmpeak="1016662" vmrss="75488" vmhwm="75488" />
        <model path="intel/face-detection-adas-0001/FP16-INT8/face-detection-adas-0001.xml" precision="FP16-INT8" test="create_exenetwork" device="GPU" vmsize="2387782" vmpeak="2442908" vmrss="478842" vmhwm="864099" />
        <model path="intel/face-detection-adas-0001/FP16-INT8/face-detection-adas-0001.xml" precision="FP16-INT8" test="infer_request_inference" device="CPU" vmsize="1003860" vmpeak="1011337" vmrss="86840" vmhwm="86840" />
        <model path="intel/face-detection-adas-0001/FP16-INT8/face-detection-adas-0001.xml" precision="FP16-INT8" test="infer_request_inference" device="GPU" vmsize="2382447" vmpeak="2382447" vmrss="488930" vmhwm="863434" />
        <model path="intel/face-detection-adas-0001/FP16-INT8/face-detection-adas-0001.xml" precision="FP16-INT8" test="inference_with_streams" device="CPU" vmsize="932084" vmpeak="1013350" vmrss="107224" vmhwm="107224" />
        <model path="intel/face-detection-adas-0001/FP16-INT8/face-detection-adas-0001.xml" precision="FP16-INT8" test="inference_with_streams" device="GPU" vmsize="2482308" vmpeak="2533445" vmrss="501945" vmhwm="867765" />
        <model path="intel/faster-rcnn-resnet101-coco-sparse-60-0001/FP16-INT8/faster-rcnn-resnet101-coco-sparse-60-0001.xml" precision="FP16-INT8" test="create_exenetwork" device="CPU" vmsize="2671302" vmpeak="2671302" vmrss="204802" vmhwm="204802" />
        <model path="intel/faster-rcnn-resnet101-coco-sparse-60-0001/FP16-INT8/faster-rcnn-resnet101-coco-sparse-60-0001.xml" precision="FP16-INT8" test="create_exenetwork" device="GPU" vmsize="4467044" vmpeak="4467044" vmrss="3262246" vmhwm="3262246" />
        <model path="intel/faster-rcnn-resnet101-coco-sparse-60-0001/FP16-INT8/faster-rcnn-resnet101-coco-sparse-60-0001.xml" precision="FP16-INT8" test="infer_request_inference" device="CPU" vmsize="2869167" vmpeak="2953158" vmrss="1736451" vmhwm="1736451" />
        <model path="intel/faster-rcnn-resnet101-coco-sparse-60-0001/FP16-INT8/faster-rcnn-resnet101-coco-sparse-60-0001.xml" precision="FP16-INT8" test="infer_request_inference" device="GPU" vmsize="4556806" vmpeak="4642003" vmrss="3289228" vmhwm="3289228" />
        <model path="intel/faster-rcnn-resnet101-coco-sparse-60-0001/FP16-INT8/faster-rcnn-resnet101-coco-sparse-60-0001.xml" precision="FP16-INT8" test="inference_with_streams" device="CPU" vmsize="4667946" vmpeak="4750439" vmrss="1837128" vmhwm="1837128" />
        <model path="intel/faster-rcnn-resnet101-coco-sparse-60-0001/FP16-INT8/faster-rcnn-resnet101-coco-sparse-60-0001.xml" precision="FP16-INT8" test="inference_with_streams" device="GPU" vmsize="6565946" vmpeak="6651143" vmrss="5227102" vmhwm="5227102" />
        <model path="intel/human-pose-estimation-0001/FP16-INT8/human-pose-estimation-0001.xml" precision="FP16-INT8" test="create_exenetwork" device="CPU" vmsize="939816" vmpeak="984178" vmrss="46618" vmhwm="46618" />
        <model path="intel/human-pose-estimation-0001/FP16-INT8/human-pose-estimation-0001.xml" precision="FP16-INT8" test="create_exenetwork" device="GPU" vmsize="1939158" vmpeak="1943188" vmrss="485128" vmhwm="767988" />
        <model path="intel/human-pose-estimation-0001/FP16-INT8/human-pose-estimation-0001.xml" precision="FP16-INT8" test="infer_request_inference" device="CPU" vmsize="941621" vmpeak="941621" vmrss="51168" vmhwm="51168" />
        <model path="intel/human-pose-estimation-0001/FP16-INT8/human-pose-estimation-0001.xml" precision="FP16-INT8" test="infer_request_inference" device="GPU" vmsize="2018276" vmpeak="2103472" vmrss="477120" vmhwm="744447" />
        <model path="intel/human-pose-estimation-0001/FP16-INT8/human-pose-estimation-0001.xml" precision="FP16-INT8" test="inference_with_streams" device="CPU" vmsize="1259580" vmpeak="1344184" vmrss="66222" vmhwm="66222" />
        <model path="intel/human-pose-estimation-0001/FP16-INT8/human-pose-estimation-0001.xml" precision="FP16-INT8" test="inference_with_streams" device="GPU" vmsize="2139228" vmpeak="2224424" vmrss="507405" vmhwm="764634" />
        <model path="intel/image-retrieval-0001/FP16-INT8/image-retrieval-0001.xml" precision="FP16-INT8" test="create_exenetwork" device="CPU" vmsize="938875" vmpeak="938875" vmrss="44480" vmhwm="44480" />
        <model path="intel/image-retrieval-0001/FP16-INT8/image-retrieval-0001.xml" precision="FP16-INT8" test="create_exenetwork" device="GPU" vmsize="1925804" vmpeak="1949838" vmrss="597656" vmhwm="1006558" />
        <model path="intel/image-retrieval-0001/FP16-INT8/image-retrieval-0001.xml" precision="FP16-INT8" test="infer_request_inference" device="CPU" vmsize="939666" vmpeak="939666" vmrss="45905" vmhwm="45905" />
        <model path="intel/image-retrieval-0001/FP16-INT8/image-retrieval-0001.xml" precision="FP16-INT8" test="infer_request_inference" device="GPU" vmsize="2010569" vmpeak="2095766" vmrss="603959" vmhwm="982862" />
        <model path="intel/image-retrieval-0001/FP16-INT8/image-retrieval-0001.xml" precision="FP16-INT8" test="inference_with_streams" device="CPU" vmsize="1077174" vmpeak="1077944" vmrss="57236" vmhwm="57236" />
        <model path="intel/image-retrieval-0001/FP16-INT8/image-retrieval-0001.xml" precision="FP16-INT8" test="inference_with_streams" device="GPU" vmsize="2110050" vmpeak="2195247" vmrss="605082" vmhwm="977121" />
        <model path="intel/landmarks-regression-retail-0009/FP16-INT8/landmarks-regression-retail-0009.xml" precision="FP16-INT8" test="create_exenetwork" device="CPU" vmsize="928345" vmpeak="1001228" vmrss="50180" vmhwm="50180" />
        <model path="intel/landmarks-regression-retail-0009/FP16-INT8/landmarks-regression-retail-0009.xml" precision="FP16-INT8" test="create_exenetwork" device="GPU" vmsize="2315144" vmpeak="2387871" vmrss="242174" vmhwm="337043" />
        <model path="intel/landmarks-regression-retail-0009/FP16-INT8/landmarks-regression-retail-0009.xml" precision="FP16-INT8" test="infer_request_inference" device="CPU" vmsize="928350" vmpeak="1001234" vmrss="50299" vmhwm="50299" />
        <model path="intel/landmarks-regression-retail-0009/FP16-INT8/landmarks-regression-retail-0009.xml" precision="FP16-INT8" test="infer_request_inference" device="GPU" vmsize="2309892" vmpeak="2382551" vmrss="243614" vmhwm="336778" />
        <model path="intel/landmarks-regression-retail-0009/FP16-INT8/landmarks-regression-retail-0009.xml" precision="FP16-INT8" test="inference_with_streams" device="CPU" vmsize="663421" vmpeak="663421" vmrss="56180" vmhwm="56180" />
        <model path="intel/landmarks-regression-retail-0009/FP16-INT8/landmarks-regression-retail-0009.xml" precision="FP16-INT8" test="inference_with_streams" device="GPU" vmsize="2411078" vmpeak="2483634" vmrss="244836" vmhwm="337672" />
        <model path="intel/license-plate-recognition-barrier-0001/FP16-INT8/license-plate-recognition-barrier-0001.xml" precision="FP16-INT8" test="create_exenetwork" device="CPU" vmsize="950081" vmpeak="950081" vmrss="60595" vmhwm="60595" />
        <model path="intel/license-plate-recognition-barrier-0001/FP16-INT8/license-plate-recognition-barrier-0001.xml" precision="FP16-INT8" test="create_exenetwork" device="GPU" vmsize="2364060" vmpeak="2438191" vmrss="339872" vmhwm="439956" />
        <model path="intel/license-plate-recognition-barrier-0001/FP16-INT8/license-plate-recognition-barrier-0001.xml" precision="FP16-INT8" test="infer_request_inference" device="CPU" vmsize="950081" vmpeak="950081" vmrss="61417" vmhwm="61417" />
        <model path="intel/license-plate-recognition-barrier-0001/FP16-INT8/license-plate-recognition-barrier-0001.xml" precision="FP16-INT8" test="infer_request_inference" device="GPU" vmsize="2369390" vmpeak="2443511" vmrss="347744" vmhwm="447236" />
        <model path="intel/license-plate-recognition-barrier-0001/FP16-INT8/license-plate-recognition-barrier-0001.xml" precision="FP16-INT8" test="inference_with_streams" device="CPU" vmsize="687544" vmpeak="740646" vmrss="69430" vmhwm="69430" />
        <model path="intel/license-plate-recognition-barrier-0001/FP16-INT8/license-plate-recognition-barrier-0001.xml" precision="FP16-INT8" test="inference_with_streams" device="GPU" vmsize="2454597" vmpeak="2528770" vmrss="349278" vmhwm="447491" />
        <model path="intel/person-attributes-recognition-crossroad-0230/FP16-INT8/person-attributes-recognition-crossroad-0230.xml" precision="FP16-INT8" test="create_exenetwork" device="CPU" vmsize="983933" vmpeak="983933" vmrss="72332" vmhwm="72332" />
        <model path="intel/person-attributes-recognition-crossroad-0230/FP16-INT8/person-attributes-recognition-crossroad-0230.xml" precision="FP16-INT8" test="create_exenetwork" device="GPU" vmsize="2396451" vmpeak="2396451" vmrss="531034" vmhwm="935797" />
        <model path="intel/person-attributes-recognition-crossroad-0230/FP16-INT8/person-attributes-recognition-crossroad-0230.xml" precision="FP16-INT8" test="infer_request_inference" device="CPU" vmsize="983938" vmpeak="1023209" vmrss="72248" vmhwm="72248" />
        <model path="intel/person-attributes-recognition-crossroad-0230/FP16-INT8/person-attributes-recognition-crossroad-0230.xml" precision="FP16-INT8" test="infer_request_inference" device="GPU" vmsize="2396446" vmpeak="2556288" vmrss="533067" vmhwm="931533" />
        <model path="intel/person-attributes-recognition-crossroad-0230/FP16-INT8/person-attributes-recognition-crossroad-0230.xml" precision="FP16-INT8" test="inference_with_streams" device="CPU" vmsize="743423" vmpeak="769262" vmrss="87952" vmhwm="87952" />
        <model path="intel/person-attributes-recognition-crossroad-0230/FP16-INT8/person-attributes-recognition-crossroad-0230.xml" precision="FP16-INT8" test="inference_with_streams" device="GPU" vmsize="2497622" vmpeak="2497622" vmrss="556717" vmhwm="933930" />
        <model path="intel/person-detection-action-recognition-0005/FP16-INT8/person-detection-action-recognition-0005.xml" precision="FP16-INT8" test="create_exenetwork" device="CPU" vmsize="1059536" vmpeak="1059536" vmrss="143696" vmhwm="143696" />
        <model path="intel/person-detection-action-recognition-0005/FP16-INT8/person-detection-action-recognition-0005.xml" precision="FP16-INT8" test="create_exenetwork" device="GPU" vmsize="2693542" vmpeak="2693542" vmrss="702998" vmhwm="1271020" />
        <model path="intel/person-detection-action-recognition-0005/FP16-INT8/person-detection-action-recognition-0005.xml" precision="FP16-INT8" test="infer_request_inference" device="CPU" vmsize="1059536" vmpeak="1059536" vmrss="155313" vmhwm="155313" />
        <model path="intel/person-detection-action-recognition-0005/FP16-INT8/person-detection-action-recognition-0005.xml" precision="FP16-INT8" test="infer_request_inference" device="GPU" vmsize="2677573" vmpeak="2677573" vmrss="770499" vmhwm="1275331" />
        <model path="intel/person-detection-action-recognition-0005/FP16-INT8/person-detection-action-recognition-0005.xml" precision="FP16-INT8" test="inference_with_streams" device="CPU" vmsize="803197" vmpeak="803197" vmrss="211312" vmhwm="211312" />
        <model path="intel/person-detection-action-recognition-0005/FP16-INT8/person-detection-action-recognition-0005.xml" precision="FP16-INT8" test="inference_with_streams" device="GPU" vmsize="2773425" vmpeak="2773425" vmrss="791840" vmhwm="1276901" />
        <model path="intel/person-detection-action-recognition-0006/FP16-INT8/person-detection-action-recognition-0006.xml" precision="FP16-INT8" test="create_exenetwork" device="CPU" vmsize="1083638" vmpeak="1083638" vmrss="154330" vmhwm="154330" />
        <model path="intel/person-detection-action-recognition-0006/FP16-INT8/person-detection-action-recognition-0006.xml" precision="FP16-INT8" test="create_exenetwork" device="GPU" vmsize="2728663" vmpeak="2728663" vmrss="731598" vmhwm="1315293" />
        <model path="intel/person-detection-action-recognition-0006/FP16-INT8/person-detection-action-recognition-0006.xml" precision="FP16-INT8" test="infer_request_inference" device="CPU" vmsize="1083638" vmpeak="1083638" vmrss="167034" vmhwm="167034" />
        <model path="intel/person-detection-action-recognition-0006/FP16-INT8/person-detection-action-recognition-0006.xml" precision="FP16-INT8" test="infer_request_inference" device="GPU" vmsize="2733998" vmpeak="2733998" vmrss="792552" vmhwm="1315870" />
        <model path="intel/person-detection-action-recognition-0006/FP16-INT8/person-detection-action-recognition-0006.xml" precision="FP16-INT8" test="inference_with_streams" device="CPU" vmsize="849435" vmpeak="849435" vmrss="228550" vmhwm="228550" />
        <model path="intel/person-detection-action-recognition-0006/FP16-INT8/person-detection-action-recognition-0006.xml" precision="FP16-INT8" test="inference_with_streams" device="GPU" vmsize="2819195" vmpeak="2819195" vmrss="821158" vmhwm="1321034" />
        <model path="intel/person-detection-action-recognition-teacher-0002/FP16-INT8/person-detection-action-recognition-teacher-0002.xml" precision="FP16-INT8" test="create_exenetwork" device="CPU" vmsize="1074772" vmpeak="1074772" vmrss="87604" vmhwm="87604" />
        <model path="intel/person-detection-action-recognition-teacher-0002/FP16-INT8/person-detection-action-recognition-teacher-0002.xml" precision="FP16-INT8" test="create_exenetwork" device="GPU" vmsize="2742277" vmpeak="2762510" vmrss="1678019" vmhwm="2070738" />
        <model path="intel/person-detection-action-recognition-teacher-0002/FP16-INT8/person-detection-action-recognition-teacher-0002.xml" precision="FP16-INT8" test="infer_request_inference" device="CPU" vmsize="1078958" vmpeak="1078958" vmrss="93584" vmhwm="93584" />
        <model path="intel/person-detection-action-recognition-teacher-0002/FP16-INT8/person-detection-action-recognition-teacher-0002.xml" precision="FP16-INT8" test="infer_request_inference" device="GPU" vmsize="2822476" vmpeak="2907673" vmrss="1663017" vmhwm="2058227" />
        <model path="intel/person-detection-action-recognition-teacher-0002/FP16-INT8/person-detection-action-recognition-teacher-0002.xml" precision="FP16-INT8" test="inference_with_streams" device="CPU" vmsize="1512357" vmpeak="1597346" vmrss="126666" vmhwm="126666" />
        <model path="intel/person-detection-action-recognition-teacher-0002/FP16-INT8/person-detection-action-recognition-teacher-0002.xml" precision="FP16-INT8" test="inference_with_streams" device="GPU" vmsize="2953698" vmpeak="3038895" vmrss="1709531" vmhwm="2073838" />
        <model path="intel/person-detection-asl-0001/FP16-INT8/person-detection-asl-0001.xml" precision="FP16-INT8" test="create_exenetwork" device="CPU" vmsize="1072396" vmpeak="1106596" vmrss="100859" vmhwm="100859" />
        <model path="intel/person-detection-asl-0001/FP16-INT8/person-detection-asl-0001.xml" precision="FP16-INT8" test="create_exenetwork" device="GPU" vmsize="2491169" vmpeak="2550116" vmrss="645788" vmhwm="1131338" />
        <model path="intel/person-detection-asl-0001/FP16-INT8/person-detection-asl-0001.xml" precision="FP16-INT8" test="infer_request_inference" device="CPU" vmsize="1078069" vmpeak="1078069" vmrss="106048" vmhwm="106048" />
        <model path="intel/person-detection-asl-0001/FP16-INT8/person-detection-asl-0001.xml" precision="FP16-INT8" test="infer_request_inference" device="GPU" vmsize="2485844" vmpeak="2485844" vmrss="689546" vmhwm="1122284" />
        <model path="intel/person-detection-asl-0001/FP16-INT8/person-detection-asl-0001.xml" precision="FP16-INT8" test="inference_with_streams" device="CPU" vmsize="1120750" vmpeak="1120750" vmrss="131669" vmhwm="131669" />
        <model path="intel/person-detection-asl-0001/FP16-INT8/person-detection-asl-0001.xml" precision="FP16-INT8" test="inference_with_streams" device="GPU" vmsize="2581701" vmpeak="2640658" vmrss="698594" vmhwm="1113361" />
        <model path="intel/person-detection-raisinghand-recognition-0001/FP16-INT8/person-detection-raisinghand-recognition-0001.xml" precision="FP16-INT8" test="create_exenetwork" device="CPU" vmsize="1056993" vmpeak="1056993" vmrss="149318" vmhwm="149318" />
        <model path="intel/person-detection-raisinghand-recognition-0001/FP16-INT8/person-detection-raisinghand-recognition-0001.xml" precision="FP16-INT8" test="create_exenetwork" device="GPU" vmsize="2677214" vmpeak="2677214" vmrss="714334" vmhwm="1280068" />
        <model path="intel/person-detection-raisinghand-recognition-0001/FP16-INT8/person-detection-raisinghand-recognition-0001.xml" precision="FP16-INT8" test="infer_request_inference" device="CPU" vmsize="1056993" vmpeak="1056993" vmrss="158511" vmhwm="158511" />
        <model path="intel/person-detection-raisinghand-recognition-0001/FP16-INT8/person-detection-raisinghand-recognition-0001.xml" precision="FP16-INT8" test="infer_request_inference" device="GPU" vmsize="2677214" vmpeak="2677214" vmrss="754660" vmhwm="1268030" />
        <model path="intel/person-detection-raisinghand-recognition-0001/FP16-INT8/person-detection-raisinghand-recognition-0001.xml" precision="FP16-INT8" test="inference_with_streams" device="CPU" vmsize="800857" vmpeak="800857" vmrss="216096" vmhwm="216096" />
        <model path="intel/person-detection-raisinghand-recognition-0001/FP16-INT8/person-detection-raisinghand-recognition-0001.xml" precision="FP16-INT8" test="inference_with_streams" device="GPU" vmsize="2778396" vmpeak="2778396" vmrss="770208" vmhwm="1270796" />
        <model path="intel/person-detection-retail-0002/FP16-INT8/person-detection-retail-0002.xml" precision="FP16-INT8" test="create_exenetwork" device="CPU" vmsize="1016345" vmpeak="1016345" vmrss="65041" vmhwm="65041" />
        <model path="intel/person-detection-retail-0002/FP16-INT8/person-detection-retail-0002.xml" precision="FP16-INT8" test="create_exenetwork" device="GPU" vmsize="2129472" vmpeak="2134132" vmrss="973185" vmhwm="1436812" />
        <model path="intel/person-detection-retail-0002/FP16-INT8/person-detection-retail-0002.xml" precision="FP16-INT8" test="infer_request_inference" device="CPU" vmsize="1024571" vmpeak="1024571" vmrss="84791" vmhwm="84791" />
        <model path="intel/person-detection-retail-0002/FP16-INT8/person-detection-retail-0002.xml" precision="FP16-INT8" test="infer_request_inference" device="GPU" vmsize="2228007" vmpeak="2228007" vmrss="987209" vmhwm="1437711" />
        <model path="intel/person-detection-retail-0002/FP16-INT8/person-detection-retail-0002.xml" precision="FP16-INT8" test="inference_with_streams" device="CPU" vmsize="1415507" vmpeak="1500704" vmrss="109579" vmhwm="109636" />
        <model path="intel/person-detection-retail-0002/FP16-INT8/person-detection-retail-0002.xml" precision="FP16-INT8" test="inference_with_streams" device="GPU" vmsize="2375094" vmpeak="2460291" vmrss="1038752" vmhwm="1435631" />
        <model path="intel/person-detection-retail-0013/FP16-INT8/person-detection-retail-0013.xml" precision="FP16-INT8" test="create_exenetwork" device="CPU" vmsize="984068" vmpeak="1017250" vmrss="101145" vmhwm="101145" />
        <model path="intel/person-detection-retail-0013/FP16-INT8/person-detection-retail-0013.xml" precision="FP16-INT8" test="create_exenetwork" device="GPU" vmsize="2481382" vmpeak="2481382" vmrss="603470" vmhwm="1085468" />
        <model path="intel/person-detection-retail-0013/FP16-INT8/person-detection-retail-0013.xml" precision="FP16-INT8" test="infer_request_inference" device="CPU" vmsize="984068" vmpeak="984068" vmrss="107452" vmhwm="107452" />
        <model path="intel/person-detection-retail-0013/FP16-INT8/person-detection-retail-0013.xml" precision="FP16-INT8" test="infer_request_inference" device="GPU" vmsize="2481377" vmpeak="2532961" vmrss="637286" vmhwm="1089400" />
        <model path="intel/person-detection-retail-0013/FP16-INT8/person-detection-retail-0013.xml" precision="FP16-INT8" test="inference_with_streams" device="CPU" vmsize="730215" vmpeak="730215" vmrss="142287" vmhwm="142287" />
        <model path="intel/person-detection-retail-0013/FP16-INT8/person-detection-retail-0013.xml" precision="FP16-INT8" test="inference_with_streams" device="GPU" vmsize="2571909" vmpeak="2571909" vmrss="639589" vmhwm="1082234" />
        <model path="intel/person-vehicle-bike-detection-crossroad-0078/FP16-INT8/person-vehicle-bike-detection-crossroad-0078.xml" precision="FP16-INT8" test="create_exenetwork" device="CPU" vmsize="1016012" vmpeak="1016012" vmrss="84682" vmhwm="84682" />
        <model path="intel/person-vehicle-bike-detection-crossroad-0078/FP16-INT8/person-vehicle-bike-detection-crossroad-0078.xml" precision="FP16-INT8" test="create_exenetwork" device="GPU" vmsize="2086245" vmpeak="2088216" vmrss="855353" vmhwm="1342120" />
        <model path="intel/person-vehicle-bike-detection-crossroad-0078/FP16-INT8/person-vehicle-bike-detection-crossroad-0078.xml" precision="FP16-INT8" test="infer_request_inference" device="CPU" vmsize="1031976" vmpeak="1031976" vmrss="105632" vmhwm="105632" />
        <model path="intel/person-vehicle-bike-detection-crossroad-0078/FP16-INT8/person-vehicle-bike-detection-crossroad-0078.xml" precision="FP16-INT8" test="infer_request_inference" device="GPU" vmsize="2190994" vmpeak="2276190" vmrss="866829" vmhwm="1328501" />
        <model path="intel/person-vehicle-bike-detection-crossroad-0078/FP16-INT8/person-vehicle-bike-detection-crossroad-0078.xml" precision="FP16-INT8" test="inference_with_streams" device="CPU" vmsize="1235972" vmpeak="1251952" vmrss="149141" vmhwm="149141" />
        <model path="intel/person-vehicle-bike-detection-crossroad-0078/FP16-INT8/person-vehicle-bike-detection-crossroad-0078.xml" precision="FP16-INT8" test="inference_with_streams" device="GPU" vmsize="2334618" vmpeak="2334618" vmrss="939302" vmhwm="1331090" />
        <model path="intel/person-vehicle-bike-detection-crossroad-1016/FP16-INT8/person-vehicle-bike-detection-crossroad-1016.xml" precision="FP16-INT8" test="create_exenetwork" device="CPU" vmsize="975442" vmpeak="975442" vmrss="79700" vmhwm="79700" />
        <model path="intel/person-vehicle-bike-detection-crossroad-1016/FP16-INT8/person-vehicle-bike-detection-crossroad-1016.xml" precision="FP16-INT8" test="create_exenetwork" device="GPU" vmsize="2425337" vmpeak="2475122" vmrss="513723" vmhwm="796406" />
        <model path="intel/person-vehicle-bike-detection-crossroad-1016/FP16-INT8/person-vehicle-bike-detection-crossroad-1016.xml" precision="FP16-INT8" test="infer_request_inference" device="CPU" vmsize="975447" vmpeak="975447" vmrss="97375" vmhwm="97375" />
        <model path="intel/person-vehicle-bike-detection-crossroad-1016/FP16-INT8/person-vehicle-bike-detection-crossroad-1016.xml" precision="FP16-INT8" test="infer_request_inference" device="GPU" vmsize="2414682" vmpeak="2464467" vmrss="506074" vmhwm="797045" />
        <model path="intel/person-vehicle-bike-detection-crossroad-1016/FP16-INT8/person-vehicle-bike-detection-crossroad-1016.xml" precision="FP16-INT8" test="inference_with_streams" device="CPU" vmsize="726840" vmpeak="726840" vmrss="122231" vmhwm="122231" />
        <model path="intel/person-vehicle-bike-detection-crossroad-1016/FP16-INT8/person-vehicle-bike-detection-crossroad-1016.xml" precision="FP16-INT8" test="inference_with_streams" device="GPU" vmsize="2514538" vmpeak="2560324" vmrss="512938" vmhwm="796385" />
        <model path="intel/single-image-super-resolution-1032/FP16-INT8/single-image-super-resolution-1032.xml" precision="FP16-INT8" test="create_exenetwork" device="CPU" vmsize="1224948" vmpeak="1287514" vmrss="92846" vmhwm="93189" />
        <model path="intel/single-image-super-resolution-1032/FP16-INT8/single-image-super-resolution-1032.xml" precision="FP16-INT8" test="create_exenetwork" device="GPU" vmsize="2414022" vmpeak="2414022" vmrss="408423" vmhwm="502158" />
        <model path="intel/single-image-super-resolution-1032/FP16-INT8/single-image-super-resolution-1032.xml" precision="FP16-INT8" test="infer_request_inference" device="CPU" vmsize="1258514" vmpeak="1258514" vmrss="343064" vmhwm="343064" />
        <model path="intel/single-image-super-resolution-1032/FP16-INT8/single-image-super-resolution-1032.xml" precision="FP16-INT8" test="infer_request_inference" device="GPU" vmsize="2455003" vmpeak="2455003" vmrss="455681" vmhwm="482461" />
        <model path="intel/single-image-super-resolution-1032/FP16-INT8/single-image-super-resolution-1032.xml" precision="FP16-INT8" test="inference_with_streams" device="CPU" vmsize="1313858" vmpeak="1313858" vmrss="444449" vmhwm="444449" />
        <model path="intel/single-image-super-resolution-1032/FP16-INT8/single-image-super-resolution-1032.xml" precision="FP16-INT8" test="inference_with_streams" device="GPU" vmsize="2610774" vmpeak="2610774" vmrss="518788" vmhwm="518788" />
        <model path="intel/unet-camvid-onnx-0001/FP16-INT8/unet-camvid-onnx-0001.xml" precision="FP16-INT8" test="create_exenetwork" device="CPU" vmsize="1095291" vmpeak="1095291" vmrss="140348" vmhwm="140348" />
        <model path="intel/unet-camvid-onnx-0001/FP16-INT8/unet-camvid-onnx-0001.xml" precision="FP16-INT8" test="create_exenetwork" device="GPU" vmsize="2450952" vmpeak="2540376" vmrss="396281" vmhwm="681761" />
        <model path="intel/unet-camvid-onnx-0001/FP16-INT8/unet-camvid-onnx-0001.xml" precision="FP16-INT8" test="infer_request_inference" device="CPU" vmsize="1106060" vmpeak="1106060" vmrss="225212" vmhwm="225212" />
        <model path="intel/unet-camvid-onnx-0001/FP16-INT8/unet-camvid-onnx-0001.xml" precision="FP16-INT8" test="infer_request_inference" device="GPU" vmsize="2456277" vmpeak="2545701" vmrss="401928" vmhwm="688381" />
        <model path="intel/unet-camvid-onnx-0001/FP16-INT8/unet-camvid-onnx-0001.xml" precision="FP16-INT8" test="inference_with_streams" device="CPU" vmsize="943675" vmpeak="963466" vmrss="278174" vmhwm="278174" />
        <model path="intel/unet-camvid-onnx-0001/FP16-INT8/unet-camvid-onnx-0001.xml" precision="FP16-INT8" test="inference_with_streams" device="GPU" vmsize="2547090" vmpeak="2665379" vmrss="416847" vmhwm="678844" />
        <model path="intel/vehicle-attributes-recognition-barrier-0039/FP16-INT8/vehicle-attributes-recognition-barrier-0039.xml" precision="FP16-INT8" test="create_exenetwork" device="CPU" vmsize="935152" vmpeak="1001800" vmrss="52691" vmhwm="52691" />
        <model path="intel/vehicle-attributes-recognition-barrier-0039/FP16-INT8/vehicle-attributes-recognition-barrier-0039.xml" precision="FP16-INT8" test="create_exenetwork" device="GPU" vmsize="2311280" vmpeak="2387944" vmrss="265673" vmhwm="384113" />
        <model path="intel/vehicle-attributes-recognition-barrier-0039/FP16-INT8/vehicle-attributes-recognition-barrier-0039.xml" precision="FP16-INT8" test="infer_request_inference" device="CPU" vmsize="935152" vmpeak="1001800" vmrss="53388" vmhwm="53388" />
        <model path="intel/vehicle-attributes-recognition-barrier-0039/FP16-INT8/vehicle-attributes-recognition-barrier-0039.xml" precision="FP16-INT8" test="infer_request_inference" device="GPU" vmsize="2311280" vmpeak="2387944" vmrss="266921" vmhwm="384191" />
        <model path="intel/vehicle-attributes-recognition-barrier-0039/FP16-INT8/vehicle-attributes-recognition-barrier-0039.xml" precision="FP16-INT8" test="inference_with_streams" device="CPU" vmsize="672172" vmpeak="736491" vmrss="57709" vmhwm="57709" />
        <model path="intel/vehicle-attributes-recognition-barrier-0039/FP16-INT8/vehicle-attributes-recognition-barrier-0039.xml" precision="FP16-INT8" test="inference_with_streams" device="GPU" vmsize="2407132" vmpeak="2407132" vmrss="268127" vmhwm="384248" />
        <model path="intel/vehicle-detection-adas-0002/FP16-INT8/vehicle-detection-adas-0002.xml" precision="FP16-INT8" test="create_exenetwork" device="CPU" vmsize="991229" vmpeak="1010365" vmrss="71385" vmhwm="71385" />
        <model path="intel/vehicle-detection-adas-0002/FP16-INT8/vehicle-detection-adas-0002.xml" precision="FP16-INT8" test="create_exenetwork" device="GPU" vmsize="2372489" vmpeak="2372489" vmrss="460434" vmhwm="802084" />
        <model path="intel/vehicle-detection-adas-0002/FP16-INT8/vehicle-detection-adas-0002.xml" precision="FP16-INT8" test="infer_request_inference" device="CPU" vmsize="991224" vmpeak="991224" vmrss="85014" vmhwm="85014" />
        <model path="intel/vehicle-detection-adas-0002/FP16-INT8/vehicle-detection-adas-0002.xml" precision="FP16-INT8" test="infer_request_inference" device="GPU" vmsize="2377814" vmpeak="2377814" vmrss="466284" vmhwm="821542" />
        <model path="intel/vehicle-detection-adas-0002/FP16-INT8/vehicle-detection-adas-0002.xml" precision="FP16-INT8" test="inference_with_streams" device="CPU" vmsize="738722" vmpeak="738722" vmrss="103381" vmhwm="103381" />
        <model path="intel/vehicle-detection-adas-0002/FP16-INT8/vehicle-detection-adas-0002.xml" precision="FP16-INT8" test="inference_with_streams" device="GPU" vmsize="2467020" vmpeak="2520720" vmrss="474416" vmhwm="805178" />
        <model path="intel/yolo-v2-ava-0001/FP16-INT8/yolo-v2-ava-0001.xml" precision="FP16-INT8" test="create_exenetwork" device="CPU" vmsize="1089717" vmpeak="1089717" vmrss="186113" vmhwm="186113" />
        <model path="intel/yolo-v2-ava-0001/FP16-INT8/yolo-v2-ava-0001.xml" precision="FP16-INT8" test="create_exenetwork" device="GPU" vmsize="2487726" vmpeak="2713334" vmrss="381763" vmhwm="804804" />
        <model path="intel/yolo-v2-ava-0001/FP16-INT8/yolo-v2-ava-0001.xml" precision="FP16-INT8" test="infer_request_inference" device="CPU" vmsize="1095026" vmpeak="1095026" vmrss="201026" vmhwm="201026" />
        <model path="intel/yolo-v2-ava-0001/FP16-INT8/yolo-v2-ava-0001.xml" precision="FP16-INT8" test="infer_request_inference" device="GPU" vmsize="2493046" vmpeak="2665213" vmrss="389188" vmhwm="826228" />
        <model path="intel/yolo-v2-ava-0001/FP16-INT8/yolo-v2-ava-0001.xml" precision="FP16-INT8" test="inference_with_streams" device="CPU" vmsize="895221" vmpeak="895221" vmrss="276676" vmhwm="276676" />
        <model path="intel/yolo-v2-ava-0001/FP16-INT8/yolo-v2-ava-0001.xml" precision="FP16-INT8" test="inference_with_streams" device="GPU" vmsize="2583573" vmpeak="2755745" vmrss="389880" vmhwm="805381" />
        <model path="intel/yolo-v2-ava-sparse-35-0001/FP16-INT8/yolo-v2-ava-sparse-35-0001.xml" precision="FP16-INT8" test="create_exenetwork" device="CPU" vmsize="1089701" vmpeak="1089701" vmrss="186342" vmhwm="186342" />
        <model path="intel/yolo-v2-ava-sparse-35-0001/FP16-INT8/yolo-v2-ava-sparse-35-0001.xml" precision="FP16-INT8" test="create_exenetwork" device="GPU" vmsize="2493046" vmpeak="2718664" vmrss="391554" vmhwm="827892" />
        <model path="intel/yolo-v2-ava-sparse-35-0001/FP16-INT8/yolo-v2-ava-sparse-35-0001.xml" precision="FP16-INT8" test="infer_request_inference" device="CPU" vmsize="1089701" vmpeak="1089701" vmrss="201474" vmhwm="201474" />
        <model path="intel/yolo-v2-ava-sparse-35-0001/FP16-INT8/yolo-v2-ava-sparse-35-0001.xml" precision="FP16-INT8" test="infer_request_inference" device="GPU" vmsize="2493046" vmpeak="2665213" vmrss="396115" vmhwm="808366" />
        <model path="intel/yolo-v2-ava-sparse-35-0001/FP16-INT8/yolo-v2-ava-sparse-35-0001.xml" precision="FP16-INT8" test="inference_with_streams" device="CPU" vmsize="895221" vmpeak="895221" vmrss="276343" vmhwm="276343" />
        <model path="intel/yolo-v2-ava-sparse-35-0001/FP16-INT8/yolo-v2-ava-sparse-35-0001.xml" precision="FP16-INT8" test="inference_with_streams" device="GPU" vmsize="2588903" vmpeak="2814515" vmrss="399120" vmhwm="808485" />
        <model path="intel/yolo-v2-tiny-ava-0001/FP16-INT8/yolo-v2-tiny-ava-0001.xml" precision="FP16-INT8" test="create_exenetwork" device="CPU" vmsize="982014" vmpeak="982014" vmrss="93028" vmhwm="93028" />
        <model path="intel/yolo-v2-tiny-ava-0001/FP16-INT8/yolo-v2-tiny-ava-0001.xml" precision="FP16-INT8" test="create_exenetwork" device="GPU" vmsize="2347191" vmpeak="2483566" vmrss="262220" vmhwm="468826" />
        <model path="intel/yolo-v2-tiny-ava-0001/FP16-INT8/yolo-v2-tiny-ava-0001.xml" precision="FP16-INT8" test="infer_request_inference" device="CPU" vmsize="982014" vmpeak="1031227" vmrss="102284" vmhwm="102284" />
        <model path="intel/yolo-v2-tiny-ava-0001/FP16-INT8/yolo-v2-tiny-ava-0001.xml" precision="FP16-INT8" test="infer_request_inference" device="GPU" vmsize="2347092" vmpeak="2483644" vmrss="260977" vmhwm="466544" />
        <model path="intel/yolo-v2-tiny-ava-0001/FP16-INT8/yolo-v2-tiny-ava-0001.xml" precision="FP16-INT8" test="inference_with_streams" device="CPU" vmsize="744452" vmpeak="790093" vmrss="129688" vmhwm="129688" />
        <model path="intel/yolo-v2-tiny-ava-0001/FP16-INT8/yolo-v2-tiny-ava-0001.xml" precision="FP16-INT8" test="inference_with_streams" device="GPU" vmsize="2437624" vmpeak="2574176" vmrss="261565" vmhwm="466658" />
        <model path="public/Sphereface/FP16/Sphereface.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="1219244" vmpeak="1219244" vmrss="339170" vmhwm="339170" />
        <model path="public/Sphereface/FP16/Sphereface.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2419872" vmpeak="2546018" vmrss="381508" vmhwm="542890" />
        <model path="public/Sphereface/FP16/Sphereface.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="1219774" vmpeak="1219774" vmrss="346850" vmhwm="346850" />
        <model path="public/Sphereface/FP16/Sphereface.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2403897" vmpeak="2474373" vmrss="384488" vmhwm="544544" />
        <model path="public/Sphereface/FP16/Sphereface.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="1319432" vmpeak="1319432" vmrss="441017" vmhwm="441017" />
        <model path="public/Sphereface/FP16/Sphereface.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2505074" vmpeak="2633280" vmrss="383812" vmhwm="543249" />
        <model path="public/Sphereface/FP32/Sphereface.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="1160868" vmpeak="1160868" vmrss="280144" vmhwm="280144" />
        <model path="public/Sphereface/FP32/Sphereface.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2466828" vmpeak="2650419" vmrss="459908" vmhwm="678381" />
        <model path="public/Sphereface/FP32/Sphereface.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="1161399" vmpeak="1161399" vmrss="288355" vmhwm="288355" />
        <model path="public/Sphereface/FP32/Sphereface.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2461503" vmpeak="2645084" vmrss="446789" vmhwm="659838" />
        <model path="public/Sphereface/FP32/Sphereface.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="1017432" vmpeak="1017432" vmrss="411585" vmhwm="411585" />
        <model path="public/Sphereface/FP32/Sphereface.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2557360" vmpeak="2685207" vmrss="441521" vmhwm="657930" />
        <model path="public/alexnet/FP16/alexnet.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="1602577" vmpeak="1602577" vmrss="716783" vmhwm="716783" />
        <model path="public/alexnet/FP16/alexnet.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2507393" vmpeak="2745610" vmrss="468338" vmhwm="719794" />
        <model path="public/alexnet/FP16/alexnet.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="1603108" vmpeak="1603108" vmrss="722430" vmhwm="722430" />
        <model path="public/alexnet/FP16/alexnet.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2496743" vmpeak="2734960" vmrss="466928" vmhwm="716882" />
        <model path="public/alexnet/FP16/alexnet.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="1773844" vmpeak="1773844" vmrss="889792" vmhwm="889792" />
        <model path="public/alexnet/FP16/alexnet.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2598762" vmpeak="2836137" vmrss="462810" vmhwm="713065" />
        <model path="public/alexnet/FP32/alexnet.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="1549652" vmpeak="1549652" vmrss="667045" vmhwm="667045" />
        <model path="public/alexnet/FP32/alexnet.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2651620" vmpeak="3044532" vmrss="623365" vmhwm="1029064" />
        <model path="public/alexnet/FP32/alexnet.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="1550182" vmpeak="1550182" vmrss="675344" vmhwm="675344" />
        <model path="public/alexnet/FP32/alexnet.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2651620" vmpeak="3044532" vmrss="621301" vmhwm="1028050" />
        <model path="public/alexnet/FP32/alexnet.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="1598178" vmpeak="1598178" vmrss="988312" vmhwm="988312" />
        <model path="public/alexnet/FP32/alexnet.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2748309" vmpeak="3140389" vmrss="616709" vmhwm="1021238" />
        <model path="public/brain-tumor-segmentation-0001/FP16/brain-tumor-segmentation-0001.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="2658853" vmpeak="2658853" vmrss="602888" vmhwm="602888" />
        <model path="public/brain-tumor-segmentation-0001/FP16/brain-tumor-segmentation-0001.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2597436" vmpeak="2639847" vmrss="817663" vmhwm="1214709" />
        <model path="public/brain-tumor-segmentation-0001/FP16/brain-tumor-segmentation-0001.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="2744060" vmpeak="2744060" vmrss="1838044" vmhwm="1838044" />
        <model path="public/brain-tumor-segmentation-0001/FP16/brain-tumor-segmentation-0001.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2597436" vmpeak="2682654" vmrss="870230" vmhwm="1214647" />
        <model path="public/brain-tumor-segmentation-0001/FP16/brain-tumor-segmentation-0001.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="3865258" vmpeak="3950466" vmrss="2092880" vmhwm="2092880" />
        <model path="public/brain-tumor-segmentation-0001/FP16/brain-tumor-segmentation-0001.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2783835" vmpeak="2869053" vmrss="939723" vmhwm="1208516" />
        <model path="public/brain-tumor-segmentation-0001/FP32/brain-tumor-segmentation-0001.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="2747841" vmpeak="2747841" vmrss="501638" vmhwm="501638" />
        <model path="public/brain-tumor-segmentation-0001/FP32/brain-tumor-segmentation-0001.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2702580" vmpeak="2836418" vmrss="920696" vmhwm="1406246" />
        <model path="public/brain-tumor-segmentation-0001/FP32/brain-tumor-segmentation-0001.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="2833048" vmpeak="2918245" vmrss="1739197" vmhwm="1739197" />
        <model path="public/brain-tumor-segmentation-0001/FP32/brain-tumor-segmentation-0001.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2702580" vmpeak="2836418" vmrss="942245" vmhwm="1400224" />
        <model path="public/brain-tumor-segmentation-0001/FP32/brain-tumor-segmentation-0001.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="4052250" vmpeak="4137458" vmrss="1994044" vmhwm="1994044" />
        <model path="public/brain-tumor-segmentation-0001/FP32/brain-tumor-segmentation-0001.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2883649" vmpeak="3049602" vmrss="1022314" vmhwm="1400464" />
        <model path="public/brain-tumor-segmentation-0002/FP16/brain-tumor-segmentation-0002.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="1748630" vmpeak="1748630" vmrss="156520" vmhwm="156520" />
        <model path="public/brain-tumor-segmentation-0002/FP16/brain-tumor-segmentation-0002.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2450884" vmpeak="2514595" vmrss="438906" vmhwm="533286" />
        <model path="public/brain-tumor-segmentation-0002/FP16/brain-tumor-segmentation-0002.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="2094768" vmpeak="2116051" vmrss="912589" vmhwm="912589" />
        <model path="public/brain-tumor-segmentation-0002/FP16/brain-tumor-segmentation-0002.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2450890" vmpeak="2525458" vmrss="438708" vmhwm="533639" />
        <model path="public/brain-tumor-segmentation-0002/FP16/brain-tumor-segmentation-0002.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="2326038" vmpeak="2400595" vmrss="987656" vmhwm="987984" />
        <model path="public/brain-tumor-segmentation-0002/FP16/brain-tumor-segmentation-0002.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2631959" vmpeak="2706485" vmrss="525777" vmhwm="608129" />
        <model path="public/brain-tumor-segmentation-0002/FP32/brain-tumor-segmentation-0002.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="1736191" vmpeak="1736191" vmrss="144419" vmhwm="144419" />
        <model path="public/brain-tumor-segmentation-0002/FP32/brain-tumor-segmentation-0002.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2464462" vmpeak="2539087" vmrss="449160" vmhwm="555292" />
        <model path="public/brain-tumor-segmentation-0002/FP32/brain-tumor-segmentation-0002.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="2002452" vmpeak="2087649" vmrss="900754" vmhwm="900754" />
        <model path="public/brain-tumor-segmentation-0002/FP32/brain-tumor-segmentation-0002.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2459475" vmpeak="2534043" vmrss="471198" vmhwm="576586" />
        <model path="public/brain-tumor-segmentation-0002/FP32/brain-tumor-segmentation-0002.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="2313599" vmpeak="2388157" vmrss="975327" vmhwm="975327" />
        <model path="public/brain-tumor-segmentation-0002/FP32/brain-tumor-segmentation-0002.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2645536" vmpeak="2730977" vmrss="559020" vmhwm="652220" />
        <model path="public/caffenet/FP16/caffenet.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="1601886" vmpeak="1601886" vmrss="716788" vmhwm="716788" />
        <model path="public/caffenet/FP16/caffenet.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2502073" vmpeak="2740285" vmrss="487052" vmhwm="717683" />
        <model path="public/caffenet/FP16/caffenet.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="1602416" vmpeak="1602416" vmrss="721770" vmhwm="721770" />
        <model path="public/caffenet/FP16/caffenet.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2496748" vmpeak="2734960" vmrss="487406" vmhwm="719331" />
        <model path="public/caffenet/FP16/caffenet.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="1500881" vmpeak="1500881" vmrss="889506" vmhwm="889506" />
        <model path="public/caffenet/FP16/caffenet.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2604087" vmpeak="2841462" vmrss="489777" vmhwm="719851" />
        <model path="public/caffenet/FP32/caffenet.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="1554280" vmpeak="1554280" vmrss="667087" vmhwm="667087" />
        <model path="public/caffenet/FP32/caffenet.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2651599" vmpeak="3044532" vmrss="642475" vmhwm="1029116" />
        <model path="public/caffenet/FP32/caffenet.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="1549485" vmpeak="1549485" vmrss="674492" vmhwm="674492" />
        <model path="public/caffenet/FP32/caffenet.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2656945" vmpeak="3049857" vmrss="634186" vmhwm="1021888" />
        <model path="public/caffenet/FP32/caffenet.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="1596795" vmpeak="1596795" vmrss="988416" vmhwm="988416" />
        <model path="public/caffenet/FP32/caffenet.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2753634" vmpeak="3145714" vmrss="644098" vmhwm="1029132" />
        <model path="public/ctdet_coco_dlav0_512/FP16/ctdet_coco_dlav0_512.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="1214059" vmpeak="1214059" vmrss="292994" vmhwm="292994" />
        <model path="public/ctdet_coco_dlav0_512/FP16/ctdet_coco_dlav0_512.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2407449" vmpeak="2476042" vmrss="480381" vmhwm="886080" />
        <model path="public/ctdet_coco_dlav0_512/FP16/ctdet_coco_dlav0_512.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="1220726" vmpeak="1220726" vmrss="350620" vmhwm="350620" />
        <model path="public/ctdet_coco_dlav0_512/FP16/ctdet_coco_dlav0_512.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2408790" vmpeak="2470728" vmrss="488009" vmhwm="885996" />
        <model path="public/ctdet_coco_dlav0_512/FP16/ctdet_coco_dlav0_512.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="1418435" vmpeak="1425096" vmrss="462155" vmhwm="462155" />
        <model path="public/ctdet_coco_dlav0_512/FP16/ctdet_coco_dlav0_512.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2520627" vmpeak="2520627" vmrss="498882" vmhwm="864354" />
        <model path="public/ctdet_coco_dlav0_512/FP32/ctdet_coco_dlav0_512.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="1167275" vmpeak="1167275" vmrss="246500" vmhwm="246500" />
        <model path="public/ctdet_coco_dlav0_512/FP32/ctdet_coco_dlav0_512.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2453656" vmpeak="2566751" vmrss="525668" vmhwm="975041" />
        <model path="public/ctdet_coco_dlav0_512/FP32/ctdet_coco_dlav0_512.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="1173936" vmpeak="1173936" vmrss="303976" vmhwm="303976" />
        <model path="public/ctdet_coco_dlav0_512/FP32/ctdet_coco_dlav0_512.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2454992" vmpeak="2493197" vmrss="520275" vmhwm="956087" />
        <model path="public/ctdet_coco_dlav0_512/FP32/ctdet_coco_dlav0_512.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="1014873" vmpeak="1021534" vmrss="416582" vmhwm="416582" />
        <model path="public/ctdet_coco_dlav0_512/FP32/ctdet_coco_dlav0_512.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2566928" vmpeak="2594378" vmrss="569374" vmhwm="975941" />
        <model path="public/ctpn/FP16/ctpn.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="1418768" vmpeak="1418768" vmrss="299956" vmhwm="299956" />
        <model path="public/ctpn/FP16/ctpn.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2424572" vmpeak="2608096" vmrss="470782" vmhwm="633027" />
        <model path="public/ctpn/FP16/ctpn.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="1600710" vmpeak="1685018" vmrss="548012" vmhwm="548012" />
        <model path="public/ctpn/FP16/ctpn.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2426065" vmpeak="2604487" vmrss="502179" vmhwm="655538" />
        <model path="public/ctpn/FP16/ctpn.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="1491334" vmpeak="1491334" vmrss="666359" vmhwm="666359" />
        <model path="public/ctpn/FP16/ctpn.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2546060" vmpeak="2703953" vmrss="472830" vmhwm="600730" />
        <model path="public/ctpn/FP32/ctpn.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="1369352" vmpeak="1369352" vmrss="260078" vmhwm="260078" />
        <model path="public/ctpn/FP32/ctpn.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2470540" vmpeak="2602298" vmrss="536104" vmhwm="742180" />
        <model path="public/ctpn/FP32/ctpn.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="1370246" vmpeak="1370246" vmrss="507280" vmhwm="507280" />
        <model path="public/ctpn/FP32/ctpn.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2472033" vmpeak="2546710" vmrss="538324" vmhwm="740927" />
        <model path="public/ctpn/FP32/ctpn.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="1441923" vmpeak="1441923" vmrss="624046" vmhwm="624046" />
        <model path="public/ctpn/FP32/ctpn.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2597176" vmpeak="2795728" vmrss="527971" vmhwm="700455" />
        <model path="public/densenet-121/FP16/densenet-121.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="1106367" vmpeak="1106367" vmrss="186602" vmhwm="186602" />
        <model path="public/densenet-121/FP16/densenet-121.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2394844" vmpeak="2448222" vmrss="589877" vmhwm="1077060" />
        <model path="public/densenet-121/FP16/densenet-121.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="1106367" vmpeak="1106367" vmrss="198863" vmhwm="198863" />
        <model path="public/densenet-121/FP16/densenet-121.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2400169" vmpeak="2453391" vmrss="622424" vmhwm="1082432" />
        <model path="public/densenet-121/FP16/densenet-121.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="980948" vmpeak="980948" vmrss="269505" vmhwm="269505" />
        <model path="public/densenet-121/FP16/densenet-121.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2485376" vmpeak="2538598" vmrss="632268" vmhwm="1078526" />
        <model path="public/densenet-121/FP32/densenet-121.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="1082546" vmpeak="1082546" vmrss="162494" vmhwm="162494" />
        <model path="public/densenet-121/FP32/densenet-121.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2429356" vmpeak="2487466" vmrss="639964" vmhwm="1113725" />
        <model path="public/densenet-121/FP32/densenet-121.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="1082546" vmpeak="1082546" vmrss="174662" vmhwm="174662" />
        <model path="public/densenet-121/FP32/densenet-121.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2442055" vmpeak="2487466" vmrss="675636" vmhwm="1114479" />
        <model path="public/densenet-121/FP32/densenet-121.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="957127" vmpeak="957127" vmrss="246402" vmhwm="246402" />
        <model path="public/densenet-121/FP32/densenet-121.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2528718" vmpeak="2546871" vmrss="679468" vmhwm="1117277" />
        <model path="public/efficientnet-b0/FP16/efficientnet-b0.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="1024524" vmpeak="1038398" vmrss="130889" vmhwm="130889" />
        <model path="public/efficientnet-b0/FP16/efficientnet-b0.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2392842" vmpeak="2460983" vmrss="519786" vmhwm="837943" />
        <model path="public/efficientnet-b0/FP16/efficientnet-b0.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="1024524" vmpeak="1024524" vmrss="139505" vmhwm="139505" />
        <model path="public/efficientnet-b0/FP16/efficientnet-b0.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2392837" vmpeak="2460983" vmrss="526271" vmhwm="837590" />
        <model path="public/efficientnet-b0/FP16/efficientnet-b0.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="784919" vmpeak="797794" vmrss="182171" vmhwm="182171" />
        <model path="public/efficientnet-b0/FP16/efficientnet-b0.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2488694" vmpeak="2489146" vmrss="545058" vmhwm="840158" />
        <model path="public/efficientnet-b0/FP32/efficientnet-b0.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="1012648" vmpeak="1026287" vmrss="121264" vmhwm="121264" />
        <model path="public/efficientnet-b0/FP32/efficientnet-b0.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2407979" vmpeak="2487191" vmrss="552193" vmhwm="865087" />
        <model path="public/efficientnet-b0/FP32/efficientnet-b0.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="1012648" vmpeak="1034280" vmrss="130244" vmhwm="130244" />
        <model path="public/efficientnet-b0/FP32/efficientnet-b0.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2402654" vmpeak="2481866" vmrss="556467" vmhwm="862404" />
        <model path="public/efficientnet-b0/FP32/efficientnet-b0.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="776292" vmpeak="813898" vmrss="176612" vmhwm="176612" />
        <model path="public/efficientnet-b0/FP32/efficientnet-b0.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2507112" vmpeak="2583048" vmrss="544720" vmhwm="843403" />
        <model path="public/faster_rcnn_inception_resnet_v2_atrous_coco/FP16/faster_rcnn_inception_resnet_v2_atrous_coco.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="4041377" vmpeak="4106684" vmrss="1155596" vmhwm="1155596" />
        <model path="public/faster_rcnn_inception_resnet_v2_atrous_coco/FP16/faster_rcnn_inception_resnet_v2_atrous_coco.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2925707" vmpeak="3154564" vmrss="880240" vmhwm="1341553" />
        <model path="public/faster_rcnn_inception_resnet_v2_atrous_coco/FP16/faster_rcnn_inception_resnet_v2_atrous_coco.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="4222431" vmpeak="4222431" vmrss="3182670" vmhwm="3182670" />
        <model path="public/faster_rcnn_inception_resnet_v2_atrous_coco/FP16/faster_rcnn_inception_resnet_v2_atrous_coco.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2936356" vmpeak="3165214" vmrss="920155" vmhwm="1364563" />
        <model path="public/faster_rcnn_inception_resnet_v2_atrous_coco/FP16/faster_rcnn_inception_resnet_v2_atrous_coco.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="6276805" vmpeak="6362002" vmrss="3542385" vmhwm="3542385" />
        <model path="public/faster_rcnn_inception_resnet_v2_atrous_coco/FP16/faster_rcnn_inception_resnet_v2_atrous_coco.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="3021558" vmpeak="3250416" vmrss="884546" vmhwm="1344335" />
        <model path="public/faster_rcnn_inception_resnet_v2_atrous_coco/FP32/faster_rcnn_inception_resnet_v2_atrous_coco.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="4072536" vmpeak="4072536" vmrss="1001052" vmhwm="1001052" />
        <model path="public/faster_rcnn_inception_resnet_v2_atrous_coco/FP32/faster_rcnn_inception_resnet_v2_atrous_coco.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="3154304" vmpeak="3395896" vmrss="1103590" vmhwm="1584070" />
        <model path="public/faster_rcnn_inception_resnet_v2_atrous_coco/FP32/faster_rcnn_inception_resnet_v2_atrous_coco.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="4078386" vmpeak="4078386" vmrss="3033357" vmhwm="3033357" />
        <model path="public/faster_rcnn_inception_resnet_v2_atrous_coco/FP32/faster_rcnn_inception_resnet_v2_atrous_coco.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="3154304" vmpeak="3395896" vmrss="1133922" vmhwm="1605978" />
        <model path="public/faster_rcnn_inception_resnet_v2_atrous_coco/FP32/faster_rcnn_inception_resnet_v2_atrous_coco.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="6315316" vmpeak="6372100" vmrss="3398668" vmhwm="3398668" />
        <model path="public/googlenet-v1-tf/FP16/googlenet-v1-tf.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="1020562" vmpeak="1024306" vmrss="119329" vmhwm="119329" />
        <model path="public/googlenet-v1-tf/FP16/googlenet-v1-tf.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="1904156" vmpeak="1934992" vmrss="474572" vmhwm="807986" />
        <model path="public/googlenet-v1-tf/FP16/googlenet-v1-tf.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="1202307" vmpeak="1202307" vmrss="124997" vmhwm="124997" />
        <model path="public/googlenet-v1-tf/FP16/googlenet-v1-tf.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="1988771" vmpeak="2073968" vmrss="482253" vmhwm="819291" />
        <model path="public/googlenet-v1-tf/FP16/googlenet-v1-tf.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="1194705" vmpeak="1195474" vmrss="166561" vmhwm="166561" />
        <model path="public/googlenet-v1-tf/FP16/googlenet-v1-tf.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2087311" vmpeak="2087311" vmrss="458333" vmhwm="782272" />
        <model path="public/googlenet-v1-tf/FP32/googlenet-v1-tf.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="1003256" vmpeak="1008779" vmrss="101306" vmhwm="101306" />
        <model path="public/googlenet-v1-tf/FP32/googlenet-v1-tf.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="1948325" vmpeak="1987351" vmrss="546041" vmhwm="854984" />
        <model path="public/googlenet-v1-tf/FP32/googlenet-v1-tf.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="1185074" vmpeak="1270271" vmrss="107614" vmhwm="107614" />
        <model path="public/googlenet-v1-tf/FP32/googlenet-v1-tf.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2030236" vmpeak="2115432" vmrss="523603" vmhwm="833918" />
        <model path="public/googlenet-v1-tf/FP32/googlenet-v1-tf.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="1179198" vmpeak="1179968" vmrss="151647" vmhwm="151647" />
        <model path="public/googlenet-v1-tf/FP32/googlenet-v1-tf.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2143554" vmpeak="2143554" vmrss="514124" vmhwm="825801" />
        <model path="public/googlenet-v1/FP16/googlenet-v1.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="1063103" vmpeak="1063103" vmrss="152318" vmhwm="152318" />
        <model path="public/googlenet-v1/FP16/googlenet-v1.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2384865" vmpeak="2577068" vmrss="494197" vmhwm="878259" />
        <model path="public/googlenet-v1/FP16/googlenet-v1.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="1068428" vmpeak="1068428" vmrss="161605" vmhwm="161605" />
        <model path="public/googlenet-v1/FP16/googlenet-v1.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2389051" vmpeak="2582387" vmrss="515715" vmhwm="899683" />
        <model path="public/googlenet-v1/FP16/googlenet-v1.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="1100897" vmpeak="1100897" vmrss="208858" vmhwm="208858" />
        <model path="public/googlenet-v1/FP16/googlenet-v1.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2486047" vmpeak="2678244" vmrss="546166" vmhwm="922443" />
        <model path="public/googlenet-v1/FP32/googlenet-v1.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="1043697" vmpeak="1043697" vmrss="132158" vmhwm="132158" />
        <model path="public/googlenet-v1/FP32/googlenet-v1.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2490872" vmpeak="2612266" vmrss="545937" vmhwm="956061" />
        <model path="public/googlenet-v1/FP32/googlenet-v1.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="1043697" vmpeak="1043697" vmrss="141284" vmhwm="141284" />
        <model path="public/googlenet-v1/FP32/googlenet-v1.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2409966" vmpeak="2617617" vmrss="539260" vmhwm="935937" />
        <model path="public/googlenet-v1/FP32/googlenet-v1.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="807180" vmpeak="807180" vmrss="193258" vmhwm="193258" />
        <model path="public/googlenet-v1/FP32/googlenet-v1.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2505817" vmpeak="2713469" vmrss="541814" vmhwm="935942" />
        <model path="public/googlenet-v2/FP16/googlenet-v2.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="1101989" vmpeak="1101989" vmrss="206845" vmhwm="206845" />
        <model path="public/googlenet-v2/FP16/googlenet-v2.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2408099" vmpeak="2487175" vmrss="471187" vmhwm="767681" />
        <model path="public/googlenet-v2/FP16/googlenet-v2.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="1101989" vmpeak="1101989" vmrss="215139" vmhwm="215139" />
        <model path="public/googlenet-v2/FP16/googlenet-v2.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2408099" vmpeak="2487180" vmrss="447220" vmhwm="768476" />
        <model path="public/googlenet-v2/FP16/googlenet-v2.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="879174" vmpeak="879174" vmrss="286348" vmhwm="286348" />
        <model path="public/googlenet-v2/FP16/googlenet-v2.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2509280" vmpeak="2588357" vmrss="471697" vmhwm="769220" />
        <model path="public/googlenet-v2/FP32/googlenet-v2.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="1071558" vmpeak="1071558" vmrss="178448" vmhwm="178448" />
        <model path="public/googlenet-v2/FP32/googlenet-v2.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2440323" vmpeak="2543632" vmrss="526463" vmhwm="854131" />
        <model path="public/googlenet-v2/FP32/googlenet-v2.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="1252612" vmpeak="1252612" vmrss="184293" vmhwm="184293" />
        <model path="public/googlenet-v2/FP32/googlenet-v2.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2434998" vmpeak="2538307" vmrss="505445" vmhwm="825994" />
        <model path="public/googlenet-v2/FP32/googlenet-v2.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="851344" vmpeak="851344" vmrss="258242" vmhwm="258242" />
        <model path="public/googlenet-v2/FP32/googlenet-v2.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2530855" vmpeak="2634158" vmrss="515517" vmhwm="825635" />
        <model path="public/googlenet-v3/FP16/googlenet-v3.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="1270947" vmpeak="1270947" vmrss="375294" vmhwm="375294" />
        <model path="public/googlenet-v3/FP16/googlenet-v3.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2435206" vmpeak="2519155" vmrss="490282" vmhwm="932068" />
        <model path="public/googlenet-v3/FP16/googlenet-v3.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="1265622" vmpeak="1265622" vmrss="390670" vmhwm="390670" />
        <model path="public/googlenet-v3/FP16/googlenet-v3.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2424562" vmpeak="2442122" vmrss="526994" vmhwm="937279" />
        <model path="public/googlenet-v3/FP16/googlenet-v3.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="1439729" vmpeak="1439729" vmrss="536104" vmhwm="536104" />
        <model path="public/googlenet-v3/FP16/googlenet-v3.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2531063" vmpeak="2615007" vmrss="524248" vmhwm="933623" />
        <model path="public/googlenet-v3/FP32/googlenet-v3.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="1293468" vmpeak="1293468" vmrss="309379" vmhwm="309379" />
        <model path="public/googlenet-v3/FP32/googlenet-v3.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2493134" vmpeak="2562664" vmrss="560617" vmhwm="1053197" />
        <model path="public/googlenet-v3/FP32/googlenet-v3.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="1202942" vmpeak="1202942" vmrss="327808" vmhwm="327808" />
        <model path="public/googlenet-v3/FP32/googlenet-v3.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2503784" vmpeak="2743707" vmrss="564751" vmhwm="1053000" />
        <model path="public/googlenet-v3/FP32/googlenet-v3.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="1105488" vmpeak="1105488" vmrss="472836" vmhwm="472836" />
        <model path="public/googlenet-v3/FP32/googlenet-v3.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2588986" vmpeak="2828909" vmrss="596960" vmhwm="1035231" />
        <model path="public/googlenet-v4-tf/FP16/googlenet-v4-tf.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="1644281" vmpeak="1644281" vmrss="694304" vmhwm="694304" />
        <model path="public/googlenet-v4-tf/FP16/googlenet-v4-tf.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2247502" vmpeak="2375058" vmrss="979690" vmhwm="1670812" />
        <model path="public/googlenet-v4-tf/FP16/googlenet-v4-tf.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="1827103" vmpeak="1911899" vmrss="706139" vmhwm="706139" />
        <model path="public/googlenet-v4-tf/FP16/googlenet-v4-tf.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2313381" vmpeak="2398578" vmrss="991702" vmhwm="1650662" />
        <model path="public/googlenet-v4-tf/FP16/googlenet-v4-tf.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="2143013" vmpeak="2227810" vmrss="837517" vmhwm="837517" />
        <model path="public/googlenet-v4-tf/FP16/googlenet-v4-tf.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2421229" vmpeak="2506426" vmrss="1040390" vmhwm="1675710" />
        <model path="public/googlenet-v4-tf/FP32/googlenet-v4-tf.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="1429204" vmpeak="1429204" vmrss="476585" vmhwm="476585" />
        <model path="public/googlenet-v4-tf/FP32/googlenet-v4-tf.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2557022" vmpeak="2771116" vmrss="1247350" vmhwm="1980596" />
        <model path="public/googlenet-v4-tf/FP32/googlenet-v4-tf.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="1612015" vmpeak="1695449" vmrss="489678" vmhwm="489678" />
        <model path="public/googlenet-v4-tf/FP32/googlenet-v4-tf.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2641761" vmpeak="2770398" vmrss="1257432" vmhwm="2000018" />
        <model path="public/googlenet-v4-tf/FP32/googlenet-v4-tf.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="2034879" vmpeak="2036242" vmrss="729263" vmhwm="729263" />
        <model path="public/googlenet-v4-tf/FP32/googlenet-v4-tf.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2742147" vmpeak="2870784" vmrss="1351552" vmhwm="1997351" />
        <model path="public/i3d-rgb-tf/FP16/i3d-rgb-tf.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="1423754" vmpeak="1423754" vmrss="285911" vmhwm="285911" />
        <model path="public/i3d-rgb-tf/FP16/i3d-rgb-tf.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2443121" vmpeak="2462501" vmrss="553893" vmhwm="755554" />
        <model path="public/i3d-rgb-tf/FP16/i3d-rgb-tf.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="1665201" vmpeak="1821144" vmrss="571214" vmhwm="571214" />
        <model path="public/i3d-rgb-tf/FP16/i3d-rgb-tf.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2437796" vmpeak="2498210" vmrss="557148" vmhwm="754660" />
        <model path="public/i3d-rgb-tf/FP16/i3d-rgb-tf.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="1564919" vmpeak="1625312" vmrss="710278" vmhwm="710278" />
        <model path="public/i3d-rgb-tf/FP16/i3d-rgb-tf.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2607420" vmpeak="2667834" vmrss="627120" vmhwm="754629" />
        <model path="public/i3d-rgb-tf/FP32/i3d-rgb-tf.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="1390724" vmpeak="1390724" vmrss="252714" vmhwm="252714" />
        <model path="public/i3d-rgb-tf/FP32/i3d-rgb-tf.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2471830" vmpeak="2520174" vmrss="589565" vmhwm="819904" />
        <model path="public/i3d-rgb-tf/FP32/i3d-rgb-tf.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="1541607" vmpeak="1626804" vmrss="536619" vmhwm="536619" />
        <model path="public/i3d-rgb-tf/FP32/i3d-rgb-tf.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2474602" vmpeak="2535015" vmrss="591650" vmhwm="819790" />
        <model path="public/i3d-rgb-tf/FP32/i3d-rgb-tf.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="1533006" vmpeak="1593399" vmrss="675740" vmhwm="675740" />
        <model path="public/i3d-rgb-tf/FP32/i3d-rgb-tf.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2638027" vmpeak="2709850" vmrss="686519" vmhwm="844339" />
        <model path="public/mask_rcnn_resnet101_atrous_coco/FP16/mask_rcnn_resnet101_atrous_coco.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="3312493" vmpeak="3312493" vmrss="1124588" vmhwm="1124588" />
        <model path="public/mask_rcnn_resnet101_atrous_coco/FP16/mask_rcnn_resnet101_atrous_coco.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="3757936" vmpeak="3757936" vmrss="2413398" vmhwm="2413398" />
        <model path="public/mask_rcnn_resnet101_atrous_coco/FP16/mask_rcnn_resnet101_atrous_coco.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="3567012" vmpeak="3645153" vmrss="2452902" vmhwm="2452902" />
        <model path="public/mask_rcnn_resnet101_atrous_coco/FP16/mask_rcnn_resnet101_atrous_coco.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="3867323" vmpeak="3952520" vmrss="2464243" vmhwm="2464243" />
        <model path="public/mask_rcnn_resnet101_atrous_coco/FP16/mask_rcnn_resnet101_atrous_coco.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="5164328" vmpeak="5231038" vmrss="2626348" vmhwm="2626348" />
        <model path="public/mask_rcnn_resnet101_atrous_coco/FP16/mask_rcnn_resnet101_atrous_coco.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="5571659" vmpeak="5656856" vmrss="4054133" vmhwm="4054138" />
        <model path="public/mask_rcnn_resnet101_atrous_coco/FP32/mask_rcnn_resnet101_atrous_coco.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="2876744" vmpeak="2876744" vmrss="685786" vmhwm="685786" />
        <model path="public/mask_rcnn_resnet101_atrous_coco/FP32/mask_rcnn_resnet101_atrous_coco.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="4934425" vmpeak="5609838" vmrss="3672682" vmhwm="4177638" />
        <model path="public/mask_rcnn_resnet101_atrous_coco/FP32/mask_rcnn_resnet101_atrous_coco.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="3493204" vmpeak="3571344" vmrss="2016596" vmhwm="2016596" />
        <model path="public/mask_rcnn_resnet101_atrous_coco/FP32/mask_rcnn_resnet101_atrous_coco.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="5044150" vmpeak="5617721" vmrss="3713075" vmhwm="4196649" />
        <model path="public/mask_rcnn_resnet101_atrous_coco/FP32/mask_rcnn_resnet101_atrous_coco.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="4951252" vmpeak="5017812" vmrss="2413538" vmhwm="2413538" />
        <model path="public/mobilenet-ssd/FP16/mobilenet-ssd.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="1032512" vmpeak="1049094" vmrss="134815" vmhwm="134815" />
        <model path="public/mobilenet-ssd/FP16/mobilenet-ssd.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2349646" vmpeak="2349646" vmrss="446966" vmhwm="729300" />
        <model path="public/mobilenet-ssd/FP16/mobilenet-ssd.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="1029506" vmpeak="1029506" vmrss="148184" vmhwm="148184" />
        <model path="public/mobilenet-ssd/FP16/mobilenet-ssd.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2349651" vmpeak="2418150" vmrss="432478" vmhwm="714584" />
        <model path="public/mobilenet-ssd/FP16/mobilenet-ssd.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="1062843" vmpeak="1062843" vmrss="190158" vmhwm="190158" />
        <model path="public/mobilenet-ssd/FP16/mobilenet-ssd.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2444052" vmpeak="2508677" vmrss="457163" vmhwm="732113" />
        <model path="public/mobilenet-ssd/FP32/mobilenet-ssd.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="1015960" vmpeak="1015960" vmrss="120224" vmhwm="120224" />
        <model path="public/mobilenet-ssd/FP32/mobilenet-ssd.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2364523" vmpeak="2446600" vmrss="442031" vmhwm="737063" />
        <model path="public/mobilenet-ssd/FP32/mobilenet-ssd.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="1015960" vmpeak="1015960" vmrss="134310" vmhwm="134310" />
        <model path="public/mobilenet-ssd/FP32/mobilenet-ssd.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2364362" vmpeak="2446605" vmrss="489866" vmhwm="783515" />
        <model path="public/mobilenet-ssd/FP32/mobilenet-ssd.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="779090" vmpeak="779090" vmrss="178838" vmhwm="178838" />
        <model path="public/mobilenet-ssd/FP32/mobilenet-ssd.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2454888" vmpeak="2465106" vmrss="428656" vmhwm="718156" />
        <model path="public/mobilenet-v1-1.0-224-tf/FP16/mobilenet-v1-1.0-224-tf.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="990142" vmpeak="1031633" vmrss="104634" vmhwm="104634" />
        <model path="public/mobilenet-v1-1.0-224-tf/FP16/mobilenet-v1-1.0-224-tf.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2326911" vmpeak="2400585" vmrss="322753" vmhwm="467214" />
        <model path="public/mobilenet-v1-1.0-224-tf/FP16/mobilenet-v1-1.0-224-tf.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="990142" vmpeak="1031633" vmrss="114894" vmhwm="114894" />
        <model path="public/mobilenet-v1-1.0-224-tf/FP16/mobilenet-v1-1.0-224-tf.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2321586" vmpeak="2395260" vmrss="323434" vmhwm="467001" />
        <model path="public/mobilenet-v1-1.0-224-tf/FP16/mobilenet-v1-1.0-224-tf.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="753412" vmpeak="796151" vmrss="144055" vmhwm="144055" />
        <model path="public/mobilenet-v1-1.0-224-tf/FP16/mobilenet-v1-1.0-224-tf.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2417443" vmpeak="2417443" vmrss="325499" vmhwm="467984" />
        <model path="public/mobilenet-v1-1.0-224-tf/FP32/mobilenet-v1-1.0-224-tf.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="1159917" vmpeak="1201408" vmrss="91405" vmhwm="91405" />
        <model path="public/mobilenet-v1-1.0-224-tf/FP32/mobilenet-v1-1.0-224-tf.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2332595" vmpeak="2338180" vmrss="335155" vmhwm="489486" />
        <model path="public/mobilenet-v1-1.0-224-tf/FP32/mobilenet-v1-1.0-224-tf.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="978868" vmpeak="1020359" vmrss="104254" vmhwm="104254" />
        <model path="public/mobilenet-v1-1.0-224-tf/FP32/mobilenet-v1-1.0-224-tf.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2337920" vmpeak="2343504" vmrss="335618" vmhwm="488389" />
        <model path="public/mobilenet-v1-1.0-224-tf/FP32/mobilenet-v1-1.0-224-tf.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="742138" vmpeak="742138" vmrss="132860" vmhwm="132860" />
        <model path="public/mobilenet-v1-1.0-224-tf/FP32/mobilenet-v1-1.0-224-tf.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2433771" vmpeak="2517741" vmrss="356803" vmhwm="506994" />
        <model path="public/mobilenet-v2-1.4-224/FP16/mobilenet-v2-1.4-224.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="1035392" vmpeak="1035392" vmrss="136624" vmhwm="136624" />
        <model path="public/mobilenet-v2-1.4-224/FP16/mobilenet-v2-1.4-224.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2336453" vmpeak="2410813" vmrss="376131" vmhwm="537700" />
        <model path="public/mobilenet-v2-1.4-224/FP16/mobilenet-v2-1.4-224.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="1035398" vmpeak="1047269" vmrss="151621" vmhwm="151621" />
        <model path="public/mobilenet-v2-1.4-224/FP16/mobilenet-v2-1.4-224.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2341773" vmpeak="2422778" vmrss="379475" vmhwm="537472" />
        <model path="public/mobilenet-v2-1.4-224/FP16/mobilenet-v2-1.4-224.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="804575" vmpeak="821771" vmrss="194911" vmhwm="194911" />
        <model path="public/mobilenet-v2-1.4-224/FP16/mobilenet-v2-1.4-224.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2437624" vmpeak="2437624" vmrss="382434" vmhwm="538038" />
        <model path="public/mobilenet-v2-1.4-224/FP32/mobilenet-v2-1.4-224.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="1018778" vmpeak="1018778" vmrss="121019" vmhwm="121019" />
        <model path="public/mobilenet-v2-1.4-224/FP32/mobilenet-v2-1.4-224.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2358314" vmpeak="2371746" vmrss="372907" vmhwm="567886" />
        <model path="public/mobilenet-v2-1.4-224/FP32/mobilenet-v2-1.4-224.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="1018778" vmpeak="1018778" vmrss="134711" vmhwm="134711" />
        <model path="public/mobilenet-v2-1.4-224/FP32/mobilenet-v2-1.4-224.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2358314" vmpeak="2446740" vmrss="396645" vmhwm="569628" />
        <model path="public/mobilenet-v2-1.4-224/FP32/mobilenet-v2-1.4-224.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="787982" vmpeak="787982" vmrss="176607" vmhwm="176607" />
        <model path="public/mobilenet-v2-1.4-224/FP32/mobilenet-v2-1.4-224.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2448851" vmpeak="2462278" vmrss="379329" vmhwm="568438" />
        <model path="public/mobilenet-v2/FP16/mobilenet-v2.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="995727" vmpeak="1032564" vmrss="102575" vmhwm="102575" />
        <model path="public/mobilenet-v2/FP16/mobilenet-v2.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2327681" vmpeak="2327681" vmrss="369054" vmhwm="543025" />
        <model path="public/mobilenet-v2/FP16/mobilenet-v2.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="990402" vmpeak="990402" vmrss="111878" vmhwm="111878" />
        <model path="public/mobilenet-v2/FP16/mobilenet-v2.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2327681" vmpeak="2327681" vmrss="351504" vmhwm="523686" />
        <model path="public/mobilenet-v2/FP16/mobilenet-v2.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="749002" vmpeak="787144" vmrss="143010" vmhwm="143010" />
        <model path="public/mobilenet-v2/FP16/mobilenet-v2.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2423538" vmpeak="2423538" vmrss="353464" vmhwm="523073" />
        <model path="public/mobilenet-v2/FP32/mobilenet-v2.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="980335" vmpeak="980335" vmrss="93943" vmhwm="93943" />
        <model path="public/mobilenet-v2/FP32/mobilenet-v2.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2337285" vmpeak="2339734" vmrss="359481" vmhwm="541117" />
        <model path="public/mobilenet-v2/FP32/mobilenet-v2.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="980335" vmpeak="1017172" vmrss="102138" vmhwm="102138" />
        <model path="public/mobilenet-v2/FP32/mobilenet-v2.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2342615" vmpeak="2344908" vmrss="361727" vmhwm="539806" />
        <model path="public/mobilenet-v2/FP32/mobilenet-v2.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="738935" vmpeak="777743" vmrss="132563" vmhwm="132563" />
        <model path="public/mobilenet-v2/FP32/mobilenet-v2.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2434920" vmpeak="2435295" vmrss="384857" vmhwm="560809" />
        <model path="public/mtcnn/mtcnn-o/FP16/mtcnn-o.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="935204" vmpeak="1001254" vmrss="52306" vmhwm="52306" />
        <model path="public/mtcnn/mtcnn-o/FP16/mtcnn-o.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2342444" vmpeak="2416601" vmrss="337355" vmhwm="422869" />
        <model path="public/mtcnn/mtcnn-o/FP16/mtcnn-o.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="930410" vmpeak="998592" vmrss="57174" vmhwm="57174" />
        <model path="public/mtcnn/mtcnn-o/FP16/mtcnn-o.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2347774" vmpeak="2421926" vmrss="308422" vmhwm="417164" />
        <model path="public/mtcnn/mtcnn-o/FP16/mtcnn-o.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="667404" vmpeak="735425" vmrss="60736" vmhwm="60736" />
        <model path="public/mtcnn/mtcnn-o/FP16/mtcnn-o.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2443630" vmpeak="2517777" vmrss="307476" vmhwm="415890" />
        <model path="public/mtcnn/mtcnn-o/FP32/mtcnn-o.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="925490" vmpeak="925490" vmrss="48068" vmhwm="48068" />
        <model path="public/mtcnn/mtcnn-o/FP32/mtcnn-o.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2343910" vmpeak="2418514" vmrss="308115" vmhwm="418808" />
        <model path="public/mtcnn/mtcnn-o/FP32/mtcnn-o.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="926021" vmpeak="926021" vmrss="54444" vmhwm="54444" />
        <model path="public/mtcnn/mtcnn-o/FP32/mtcnn-o.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2343905" vmpeak="2418514" vmrss="337090" vmhwm="427830" />
        <model path="public/mtcnn/mtcnn-o/FP32/mtcnn-o.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="935344" vmpeak="935344" vmrss="59555" vmhwm="59555" />
        <model path="public/mtcnn/mtcnn-o/FP32/mtcnn-o.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2439762" vmpeak="2514366" vmrss="316586" vmhwm="426883" />
        <model path="public/mtcnn/mtcnn-r/FP16/mtcnn-r.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="928049" vmpeak="1002835" vmrss="47138" vmhwm="47138" />
        <model path="public/mtcnn/mtcnn-r/FP16/mtcnn-r.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2345876" vmpeak="2420324" vmrss="312514" vmhwm="379688" />
        <model path="public/mtcnn/mtcnn-r/FP16/mtcnn-r.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="923254" vmpeak="923254" vmrss="52119" vmhwm="52119" />
        <model path="public/mtcnn/mtcnn-r/FP16/mtcnn-r.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2345876" vmpeak="2420324" vmrss="309602" vmhwm="379002" />
        <model path="public/mtcnn/mtcnn-r/FP16/mtcnn-r.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="929042" vmpeak="929042" vmrss="51511" vmhwm="51511" />
        <model path="public/mtcnn/mtcnn-r/FP16/mtcnn-r.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2436408" vmpeak="2510856" vmrss="310663" vmhwm="378404" />
        <model path="public/mtcnn/mtcnn-r/FP32/mtcnn-r.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="920030" vmpeak="997526" vmrss="47824" vmhwm="47824" />
        <model path="public/mtcnn/mtcnn-r/FP32/mtcnn-r.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2341398" vmpeak="2341398" vmrss="324178" vmhwm="394061" />
        <model path="public/mtcnn/mtcnn-r/FP32/mtcnn-r.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="920561" vmpeak="997526" vmrss="50840" vmhwm="50840" />
        <model path="public/mtcnn/mtcnn-r/FP32/mtcnn-r.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2357378" vmpeak="2431254" vmrss="325582" vmhwm="395725" />
        <model path="public/mtcnn/mtcnn-r/FP32/mtcnn-r.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="655018" vmpeak="655018" vmrss="52868" vmhwm="52868" />
        <model path="public/mtcnn/mtcnn-r/FP32/mtcnn-r.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2442580" vmpeak="2516456" vmrss="324225" vmhwm="393177" />
        <model path="public/mask_rcnn_resnet50_atrous_coco/FP16/mask_rcnn_resnet50_atrous_coco.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="3050434" vmpeak="3050434" vmrss="704880" vmhwm="704880" />
        <model path="public/mask_rcnn_resnet50_atrous_coco/FP16/mask_rcnn_resnet50_atrous_coco.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2600119" vmpeak="3150976" vmrss="716206" vmhwm="1269002" />
        <model path="public/mask_rcnn_resnet50_atrous_coco/FP16/mask_rcnn_resnet50_atrous_coco.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="4263116" vmpeak="4312890" vmrss="2312518" vmhwm="2312518" />
        <model path="public/mask_rcnn_resnet50_atrous_coco/FP16/mask_rcnn_resnet50_atrous_coco.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2735080" vmpeak="3306352" vmrss="732565" vmhwm="1303161" />
        <model path="public/mask_rcnn_resnet50_atrous_coco/FP16/mask_rcnn_resnet50_atrous_coco.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="3009682" vmpeak="3094878" vmrss="2034224" vmhwm="2034224" />
        <model path="public/mask_rcnn_resnet50_atrous_coco/FP16/mask_rcnn_resnet50_atrous_coco.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2589475" vmpeak="3140332" vmrss="691870" vmhwm="1239971" />
        <model path="public/mask_rcnn_resnet50_atrous_coco/FP32/mask_rcnn_resnet50_atrous_coco.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="2707187" vmpeak="2707187" vmrss="536905" vmhwm="536905" />
        <model path="public/mask_rcnn_resnet50_atrous_coco/FP32/mask_rcnn_resnet50_atrous_coco.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2706012" vmpeak="3361165" vmrss="778039" vmhwm="1435158" />
        <model path="public/mask_rcnn_resnet50_atrous_coco/FP32/mask_rcnn_resnet50_atrous_coco.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="4372503" vmpeak="4422277" vmrss="2148936" vmhwm="2148936" />
        <model path="public/mask_rcnn_resnet50_atrous_coco/FP32/mask_rcnn_resnet50_atrous_coco.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2862267" vmpeak="3537835" vmrss="836087" vmhwm="1510246" />
        <model path="public/mask_rcnn_resnet50_atrous_coco/FP32/mask_rcnn_resnet50_atrous_coco.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="2938015" vmpeak="3023212" vmrss="1866872" vmhwm="1866872" />
        <model path="public/mask_rcnn_resnet50_atrous_coco/FP32/mask_rcnn_resnet50_atrous_coco.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2711332" vmpeak="3366485" vmrss="771274" vmhwm="1423084" />
        <model path="public/se-inception/FP16/se-inception.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="1124770" vmpeak="1124770" vmrss="226548" vmhwm="226548" />
        <model path="public/se-inception/FP16/se-inception.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2417204" vmpeak="2491054" vmrss="548043" vmhwm="962260" />
        <model path="public/se-inception/FP16/se-inception.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="1124770" vmpeak="1124770" vmrss="231452" vmhwm="231452" />
        <model path="public/se-inception/FP16/se-inception.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2422534" vmpeak="2433808" vmrss="574761" vmhwm="965229" />
        <model path="public/se-inception/FP16/se-inception.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="899896" vmpeak="899896" vmrss="312150" vmhwm="312150" />
        <model path="public/se-inception/FP16/se-inception.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2518386" vmpeak="2700053" vmrss="564257" vmhwm="946228" />
        <model path="public/se-inception/FP32/se-inception.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="1092000" vmpeak="1092000" vmrss="193403" vmhwm="193403" />
        <model path="public/se-inception/FP32/se-inception.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2470785" vmpeak="2504169" vmrss="581531" vmhwm="1021805" />
        <model path="public/se-inception/FP32/se-inception.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="1091994" vmpeak="1091994" vmrss="200314" vmhwm="200314" />
        <model path="public/se-inception/FP32/se-inception.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2460130" vmpeak="2556902" vmrss="609216" vmhwm="1024098" />
        <model path="public/se-inception/FP32/se-inception.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="869720" vmpeak="871624" vmrss="283363" vmhwm="283363" />
        <model path="public/se-inception/FP32/se-inception.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2550662" vmpeak="2646909" vmrss="612430" vmhwm="1024764" />
        <model path="public/se-resnet-50/FP16/se-resnet-50.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="1282023" vmpeak="1282023" vmrss="430601" vmhwm="430601" />
        <model path="public/se-resnet-50/FP16/se-resnet-50.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2456776" vmpeak="2571056" vmrss="515871" vmhwm="781809" />
        <model path="public/se-resnet-50/FP16/se-resnet-50.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="1282023" vmpeak="1282023" vmrss="444215" vmhwm="444215" />
        <model path="public/se-resnet-50/FP16/se-resnet-50.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2456771" vmpeak="2571051" vmrss="474188" vmhwm="735040" />
        <model path="public/se-resnet-50/FP16/se-resnet-50.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="1214070" vmpeak="1214070" vmrss="604692" vmhwm="604692" />
        <model path="public/se-resnet-50/FP16/se-resnet-50.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2557958" vmpeak="2672238" vmrss="528294" vmhwm="762444" />
        <model path="public/se-resnet-50/FP32/se-resnet-50.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="1389362" vmpeak="1389362" vmrss="354983" vmhwm="354983" />
        <model path="public/se-resnet-50/FP32/se-resnet-50.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2531141" vmpeak="2713126" vmrss="565562" vmhwm="876683" />
        <model path="public/se-resnet-50/FP32/se-resnet-50.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="1208308" vmpeak="1208308" vmrss="371467" vmhwm="371467" />
        <model path="public/se-resnet-50/FP32/se-resnet-50.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2536466" vmpeak="2718450" vmrss="550186" vmhwm="876922" />
        <model path="public/se-resnet-50/FP32/se-resnet-50.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="1145554" vmpeak="1145554" vmrss="534846" vmhwm="534846" />
        <model path="public/se-resnet-50/FP32/se-resnet-50.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2632318" vmpeak="2814297" vmrss="574600" vmhwm="875274" />
        <model path="public/se-resnext-50/FP16/se-resnext-50.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="1272372" vmpeak="1272372" vmrss="424309" vmhwm="424309" />
        <model path="public/se-resnext-50/FP16/se-resnext-50.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2451935" vmpeak="2568545" vmrss="495762" vmhwm="780514" />
        <model path="public/se-resnext-50/FP16/se-resnext-50.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="1272372" vmpeak="1272372" vmrss="437221" vmhwm="437221" />
        <model path="public/se-resnext-50/FP16/se-resnext-50.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2457260" vmpeak="2573870" vmrss="454292" vmhwm="730922" />
        <model path="public/se-resnext-50/FP16/se-resnext-50.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="1194096" vmpeak="1194096" vmrss="593616" vmhwm="593616" />
        <model path="public/se-resnext-50/FP16/se-resnext-50.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2550626" vmpeak="2664396" vmrss="457553" vmhwm="732997" />
        <model path="public/se-resnext-50/FP32/se-resnext-50.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="1200035" vmpeak="1200035" vmrss="351254" vmhwm="351254" />
        <model path="public/se-resnext-50/FP32/se-resnext-50.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2527158" vmpeak="2707827" vmrss="521726" vmhwm="870173" />
        <model path="public/se-resnext-50/FP32/se-resnext-50.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="1200040" vmpeak="1200040" vmrss="364868" vmhwm="364868" />
        <model path="public/se-resnext-50/FP32/se-resnext-50.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2535317" vmpeak="2713157" vmrss="552520" vmhwm="891956" />
        <model path="public/se-resnext-50/FP32/se-resnext-50.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="1126959" vmpeak="1126959" vmrss="525548" vmhwm="525548" />
        <model path="public/se-resnext-50/FP32/se-resnext-50.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2625854" vmpeak="2803684" vmrss="534929" vmhwm="871410" />
        <model path="public/ssd300/FP16/ssd300.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="1375400" vmpeak="1375400" vmrss="404430" vmhwm="404430" />
        <model path="public/ssd300/FP16/ssd300.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2401318" vmpeak="2511766" vmrss="421844" vmhwm="807029" />
        <model path="public/ssd300/FP16/ssd300.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="1465926" vmpeak="1551123" vmrss="464729" vmhwm="464729" />
        <model path="public/ssd300/FP16/ssd300.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2406643" vmpeak="2517091" vmrss="449061" vmhwm="806956" />
        <model path="public/ssd300/FP16/ssd300.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="1569578" vmpeak="1569578" vmrss="617328" vmhwm="617328" />
        <model path="public/ssd300/FP16/ssd300.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2497175" vmpeak="2607623" vmrss="451282" vmhwm="828313" />
        <model path="public/ssd300/FP32/ssd300.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="1313000" vmpeak="1313000" vmrss="333080" vmhwm="333080" />
        <model path="public/ssd300/FP32/ssd300.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2468778" vmpeak="2645115" vmrss="510551" vmhwm="940144" />
        <model path="public/ssd300/FP32/ssd300.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="1307675" vmpeak="1307675" vmrss="397540" vmhwm="397540" />
        <model path="public/ssd300/FP32/ssd300.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2484757" vmpeak="2661094" vmrss="554455" vmhwm="980678" />
        <model path="public/ssd300/FP32/ssd300.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="1501853" vmpeak="1501853" vmrss="550737" vmhwm="550737" />
        <model path="public/ssd300/FP32/ssd300.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2569954" vmpeak="2746296" vmrss="538584" vmhwm="937731" />
        <model path="public/ssd512/FP16/ssd512.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="1491994" vmpeak="1491994" vmrss="432650" vmhwm="432650" />
        <model path="public/ssd512/FP16/ssd512.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2436740" vmpeak="2534662" vmrss="515403" vmhwm="855067" />
        <model path="public/ssd512/FP16/ssd512.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="1582521" vmpeak="1667718" vmrss="610667" vmhwm="610667" />
        <model path="public/ssd512/FP16/ssd512.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2420766" vmpeak="2522452" vmrss="521237" vmhwm="855530" />
        <model path="public/ssd512/FP16/ssd512.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="1791982" vmpeak="1791982" vmrss="787592" vmhwm="787592" />
        <model path="public/ssd512/FP16/ssd512.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2532592" vmpeak="2554229" vmrss="558240" vmhwm="898367" />
        <model path="public/ssd512/FP32/ssd512.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="1421924" vmpeak="1421924" vmrss="362544" vmhwm="362544" />
        <model path="public/ssd512/FP32/ssd512.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2501194" vmpeak="2667251" vmrss="562510" vmhwm="993829" />
        <model path="public/ssd512/FP32/ssd512.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="1602978" vmpeak="1688174" vmrss="540441" vmhwm="540441" />
        <model path="public/ssd512/FP32/ssd512.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2490545" vmpeak="2656607" vmrss="577974" vmhwm="994318" />
        <model path="public/ssd512/FP32/ssd512.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="1721912" vmpeak="1721912" vmrss="717277" vmhwm="717277" />
        <model path="public/ssd512/FP32/ssd512.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2607696" vmpeak="2763108" vmrss="585717" vmhwm="994796" />
        <model path="public/ssd_mobilenet_v1_coco/FP16/ssd_mobilenet_v1_coco.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="1052698" vmpeak="1053239" vmrss="152620" vmhwm="152620" />
        <model path="public/ssd_mobilenet_v1_coco/FP16/ssd_mobilenet_v1_coco.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2340956" vmpeak="2349708" vmrss="426254" vmhwm="676665" />
        <model path="public/ssd_mobilenet_v1_coco/FP16/ssd_mobilenet_v1_coco.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="1052698" vmpeak="1052698" vmrss="165292" vmhwm="165292" />
        <model path="public/ssd_mobilenet_v1_coco/FP16/ssd_mobilenet_v1_coco.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2335626" vmpeak="2416055" vmrss="428500" vmhwm="676379" />
        <model path="public/ssd_mobilenet_v1_coco/FP16/ssd_mobilenet_v1_coco.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="833809" vmpeak="833809" vmrss="217926" vmhwm="217926" />
        <model path="public/ssd_mobilenet_v1_coco/FP16/ssd_mobilenet_v1_coco.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2443053" vmpeak="2522551" vmrss="431636" vmhwm="676457" />
        <model path="public/ssd_mobilenet_v1_coco/FP32/ssd_mobilenet_v1_coco.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="1034592" vmpeak="1035132" vmrss="134518" vmhwm="134518" />
        <model path="public/ssd_mobilenet_v1_coco/FP32/ssd_mobilenet_v1_coco.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2359562" vmpeak="2384012" vmrss="446409" vmhwm="709722" />
        <model path="public/ssd_mobilenet_v1_coco/FP32/ssd_mobilenet_v1_coco.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="1039365" vmpeak="1039365" vmrss="146593" vmhwm="146593" />
        <model path="public/ssd_mobilenet_v1_coco/FP32/ssd_mobilenet_v1_coco.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2359557" vmpeak="2384007" vmrss="448281" vmhwm="708853" />
        <model path="public/ssd_mobilenet_v1_coco/FP32/ssd_mobilenet_v1_coco.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="815157" vmpeak="816478" vmrss="198047" vmhwm="198047" />
        <model path="public/ssd_mobilenet_v1_coco/FP32/ssd_mobilenet_v1_coco.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2455788" vmpeak="2551536" vmrss="451620" vmhwm="710912" />
        <model path="public/vgg19/FP16/vgg19.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="2688535" vmpeak="2688535" vmrss="1768343" vmhwm="1768343" />
        <model path="public/vgg19/FP16/vgg19.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2717234" vmpeak="3321390" vmrss="705983" vmhwm="1295325" />
        <model path="public/vgg19/FP16/vgg19.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="2689065" vmpeak="2689065" vmrss="1805128" vmhwm="1805128" />
        <model path="public/vgg19/FP16/vgg19.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2722553" vmpeak="3326720" vmrss="705239" vmhwm="1283464" />
        <model path="public/vgg19/FP16/vgg19.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="3142443" vmpeak="3142443" vmrss="2226562" vmhwm="2226562" />
        <model path="public/vgg19/FP16/vgg19.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2818405" vmpeak="3422572" vmrss="726965" vmhwm="1304024" />
        <model path="public/vgg19/FP32/vgg19.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="2425404" vmpeak="2425404" vmrss="1508837" vmhwm="1508837" />
        <model path="public/vgg19/FP32/vgg19.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="3082034" vmpeak="4050867" vmrss="1101349" vmhwm="2014412" />
        <model path="public/vgg19/FP32/vgg19.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="2516462" vmpeak="2516462" vmrss="1546963" vmhwm="1546963" />
        <model path="public/vgg19/FP32/vgg19.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="3082034" vmpeak="4050867" vmrss="1103055" vmhwm="2016071" />
        <model path="public/vgg19/FP32/vgg19.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="2921646" vmpeak="2921646" vmrss="2282524" vmhwm="2282524" />
        <model path="public/vgg19/FP32/vgg19.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="3184906" vmpeak="4152033" vmrss="1072292" vmhwm="1983612" />
        <model path="public/yolo-v1-tiny-tf/FP16/yolo-v1-tiny-tf.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="1152798" vmpeak="1152798" vmrss="251794" vmhwm="251794" />
        <model path="public/yolo-v1-tiny-tf/FP16/yolo-v1-tiny-tf.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2351731" vmpeak="2456646" vmrss="314246" vmhwm="484307" />
        <model path="public/yolo-v1-tiny-tf/FP16/yolo-v1-tiny-tf.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="1152798" vmpeak="1152798" vmrss="273556" vmhwm="273556" />
        <model path="public/yolo-v1-tiny-tf/FP16/yolo-v1-tiny-tf.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2346406" vmpeak="2390684" vmrss="292931" vmhwm="465108" />
        <model path="public/yolo-v1-tiny-tf/FP16/yolo-v1-tiny-tf.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="987698" vmpeak="987698" vmrss="362185" vmhwm="362185" />
        <model path="public/yolo-v1-tiny-tf/FP16/yolo-v1-tiny-tf.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2450250" vmpeak="2552498" vmrss="297076" vmhwm="464001" />
        <model path="public/yolo-v1-tiny-tf/FP32/yolo-v1-tiny-tf.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="1112342" vmpeak="1112342" vmrss="210553" vmhwm="210553" />
        <model path="public/yolo-v1-tiny-tf/FP32/yolo-v1-tiny-tf.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2387512" vmpeak="2531812" vmrss="335400" vmhwm="545651" />
        <model path="public/yolo-v1-tiny-tf/FP32/yolo-v1-tiny-tf.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="1112342" vmpeak="1112342" vmrss="232882" vmhwm="232882" />
        <model path="public/yolo-v1-tiny-tf/FP32/yolo-v1-tiny-tf.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2387512" vmpeak="2531812" vmrss="333413" vmhwm="544471" />
        <model path="public/yolo-v1-tiny-tf/FP32/yolo-v1-tiny-tf.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="947268" vmpeak="947268" vmrss="320684" vmhwm="320684" />
        <model path="public/yolo-v1-tiny-tf/FP32/yolo-v1-tiny-tf.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2486031" vmpeak="2567676" vmrss="357026" vmhwm="565427" />
        <model path="public/yolo-v2-tf/FP16/yolo-v2-tf.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="1664176" vmpeak="1664176" vmrss="705338" vmhwm="705338" />
        <model path="public/yolo-v2-tf/FP16/yolo-v2-tf.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2457686" vmpeak="2636322" vmrss="433149" vmhwm="676863" />
        <model path="public/yolo-v2-tf/FP16/yolo-v2-tf.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="1658852" vmpeak="1658852" vmrss="787118" vmhwm="787118" />
        <model path="public/yolo-v2-tf/FP16/yolo-v2-tf.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2453547" vmpeak="2631033" vmrss="432021" vmhwm="675350" />
        <model path="public/yolo-v2-tf/FP16/yolo-v2-tf.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="1997626" vmpeak="1997626" vmrss="1063202" vmhwm="1063202" />
        <model path="public/yolo-v2-tf/FP16/yolo-v2-tf.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2573802" vmpeak="2726890" vmrss="457147" vmhwm="674814" />
        <model path="public/yolo-v2-tf/FP32/yolo-v2-tf.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="1528779" vmpeak="1528779" vmrss="571792" vmhwm="571792" />
        <model path="public/yolo-v2-tf/FP32/yolo-v2-tf.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2595444" vmpeak="2896930" vmrss="559956" vmhwm="932526" />
        <model path="public/yolo-v2-tf/FP32/yolo-v2-tf.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="1528779" vmpeak="1528779" vmrss="657623" vmhwm="657623" />
        <model path="public/yolo-v2-tf/FP32/yolo-v2-tf.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2595444" vmpeak="2896930" vmrss="563045" vmhwm="933842" />
        <model path="public/yolo-v2-tf/FP32/yolo-v2-tf.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="1867554" vmpeak="1867554" vmrss="933020" vmhwm="933020" />
        <model path="public/yolo-v2-tf/FP32/yolo-v2-tf.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2716339" vmpeak="2992787" vmrss="590153" vmhwm="935558" />
        <model path="public/yolo-v2-tiny-tf/FP16/yolo-v2-tiny-tf.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="1110751" vmpeak="1110751" vmrss="223412" vmhwm="223412" />
        <model path="public/yolo-v2-tiny-tf/FP16/yolo-v2-tiny-tf.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="1923818" vmpeak="1950629" vmrss="282828" vmhwm="429265" />
        <model path="public/yolo-v2-tiny-tf/FP16/yolo-v2-tiny-tf.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="1113762" vmpeak="1113762" vmrss="242008" vmhwm="242008" />
        <model path="public/yolo-v2-tiny-tf/FP16/yolo-v2-tiny-tf.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2005879" vmpeak="2091076" vmrss="280706" vmhwm="427741" />
        <model path="public/yolo-v2-tiny-tf/FP16/yolo-v2-tiny-tf.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="1237802" vmpeak="1268186" vmrss="249511" vmhwm="249511" />
        <model path="public/yolo-v2-tiny-tf/FP16/yolo-v2-tiny-tf.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2107586" vmpeak="2192782" vmrss="293467" vmhwm="428490" />
        <model path="public/yolo-v2-tiny-tf/FP32/yolo-v2-tiny-tf.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="1028014" vmpeak="1030369" vmrss="139328" vmhwm="139328" />
        <model path="public/yolo-v2-tiny-tf/FP32/yolo-v2-tiny-tf.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="1983238" vmpeak="2050245" vmrss="357052" vmhwm="495908" />
        <model path="public/yolo-v2-tiny-tf/FP32/yolo-v2-tiny-tf.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="1212078" vmpeak="1212078" vmrss="158246" vmhwm="158246" />
        <model path="public/yolo-v2-tiny-tf/FP32/yolo-v2-tiny-tf.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2068710" vmpeak="2153907" vmrss="357437" vmhwm="495237" />
        <model path="public/yolo-v2-tiny-tf/FP32/yolo-v2-tiny-tf.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="1390428" vmpeak="1475624" vmrss="220927" vmhwm="220927" />
        <model path="public/yolo-v2-tiny-tf/FP32/yolo-v2-tiny-tf.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2187723" vmpeak="2187723" vmrss="404102" vmhwm="495456" />
        <model path="public/yolo-v3-tf/FP16/yolo-v3-tf.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="1773423" vmpeak="1773423" vmrss="857984" vmhwm="857984" />
        <model path="public/yolo-v3-tf/FP16/yolo-v3-tf.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2517585" vmpeak="2697151" vmrss="488072" vmhwm="824314" />
        <model path="public/yolo-v3-tf/FP16/yolo-v3-tf.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="1954477" vmpeak="1954477" vmrss="906412" vmhwm="906412" />
        <model path="public/yolo-v3-tf/FP16/yolo-v3-tf.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2517590" vmpeak="2697167" vmrss="494858" vmhwm="824324" />
        <model path="public/yolo-v3-tf/FP16/yolo-v3-tf.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="1934363" vmpeak="2019560" vmrss="1247298" vmhwm="1247298" />
        <model path="public/yolo-v3-tf/FP16/yolo-v3-tf.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2621429" vmpeak="2798348" vmrss="521586" vmhwm="847137" />
        <model path="public/yolo-v3-tf/FP32/yolo-v3-tf.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="1613404" vmpeak="1613404" vmrss="698271" vmhwm="698271" />
        <model path="public/yolo-v3-tf/FP32/yolo-v3-tf.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2686091" vmpeak="3018012" vmrss="674294" vmhwm="1141254" />
        <model path="public/yolo-v3-tf/FP32/yolo-v3-tf.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="1703915" vmpeak="1703915" vmrss="746725" vmhwm="746725" />
        <model path="public/yolo-v3-tf/FP32/yolo-v3-tf.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2696746" vmpeak="3028324" vmrss="659703" vmhwm="1140547" />
        <model path="public/yolo-v3-tf/FP32/yolo-v3-tf.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="1683796" vmpeak="1683796" vmrss="1087616" vmhwm="1087616" />
        <model path="public/yolo-v3-tf/FP32/yolo-v3-tf.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2789940" vmpeak="3118845" vmrss="661554" vmhwm="1140505" />
        <model path="intel/action-recognition-0001/action-recognition-0001-decoder/FP16/action-recognition-0001-decoder.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="993246" vmpeak="1045787" vmrss="129251" vmhwm="129251" />
        <model path="intel/action-recognition-0001/action-recognition-0001-decoder/FP16/action-recognition-0001-decoder.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2385822" vmpeak="2469043" vmrss="318931" vmhwm="418397" />
        <model path="intel/action-recognition-0001/action-recognition-0001-decoder/FP16/action-recognition-0001-decoder.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="755986" vmpeak="809192" vmrss="170097" vmhwm="170097" />
        <model path="intel/action-recognition-0001/action-recognition-0001-decoder/FP16/action-recognition-0001-decoder.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2471029" vmpeak="2554510" vmrss="320585" vmhwm="418376" />
        <model path="intel/action-recognition-0001/action-recognition-0001-decoder/FP16/action-recognition-0001-decoder.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="993246" vmpeak="993246" vmrss="132204" vmhwm="132204" />
        <model path="intel/action-recognition-0001/action-recognition-0001-decoder/FP16/action-recognition-0001-decoder.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2375172" vmpeak="2458482" vmrss="346346" vmhwm="445478" />
        <model path="intel/action-recognition-0001/action-recognition-0001-decoder/FP32/action-recognition-0001-decoder.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="990844" vmpeak="1044716" vmrss="118809" vmhwm="118809" />
        <model path="intel/action-recognition-0001/action-recognition-0001-decoder/FP32/action-recognition-0001-decoder.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2396378" vmpeak="2499868" vmrss="346720" vmhwm="471416" />
        <model path="intel/action-recognition-0001/action-recognition-0001-decoder/FP32/action-recognition-0001-decoder.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="753584" vmpeak="815864" vmrss="164574" vmhwm="164574" />
        <model path="intel/action-recognition-0001/action-recognition-0001-decoder/FP32/action-recognition-0001-decoder.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2486759" vmpeak="2590489" vmrss="343860" vmhwm="470111" />
        <model path="intel/action-recognition-0001/action-recognition-0001-decoder/FP32/action-recognition-0001-decoder.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="996169" vmpeak="996169" vmrss="123156" vmhwm="123156" />
        <model path="intel/action-recognition-0001/action-recognition-0001-decoder/FP32/action-recognition-0001-decoder.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2396227" vmpeak="2499957" vmrss="336549" vmhwm="463736" />
        <model path="intel/action-recognition-0001/action-recognition-0001-encoder/FP16/action-recognition-0001-encoder.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="1206514" vmpeak="1206514" vmrss="324516" vmhwm="324516" />
        <model path="intel/action-recognition-0001/action-recognition-0001-encoder/FP16/action-recognition-0001-encoder.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2371028" vmpeak="2488200" vmrss="311188" vmhwm="512096" />
        <model path="intel/action-recognition-0001/action-recognition-0001-encoder/FP16/action-recognition-0001-encoder.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="1046890" vmpeak="1046890" vmrss="448957" vmhwm="448957" />
        <model path="intel/action-recognition-0001/action-recognition-0001-encoder/FP16/action-recognition-0001-encoder.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2469994" vmpeak="2589376" vmrss="321370" vmhwm="513182" />
        <model path="intel/action-recognition-0001/action-recognition-0001-encoder/FP16/action-recognition-0001-encoder.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="1206514" vmpeak="1206514" vmrss="331500" vmhwm="331500" />
        <model path="intel/action-recognition-0001/action-recognition-0001-encoder/FP16/action-recognition-0001-encoder.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2365698" vmpeak="2482875" vmrss="314251" vmhwm="512194" />
        <model path="intel/action-recognition-0001/action-recognition-0001-encoder/FP32/action-recognition-0001-encoder.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="1151675" vmpeak="1151675" vmrss="268892" vmhwm="268892" />
        <model path="intel/action-recognition-0001/action-recognition-0001-encoder/FP32/action-recognition-0001-encoder.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2420178" vmpeak="2590801" vmrss="364587" vmhwm="619543" />
        <model path="intel/action-recognition-0001/action-recognition-0001-encoder/FP32/action-recognition-0001-encoder.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="992050" vmpeak="992050" vmrss="393796" vmhwm="393796" />
        <model path="intel/action-recognition-0001/action-recognition-0001-encoder/FP32/action-recognition-0001-encoder.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2521365" vmpeak="2691982" vmrss="367697" vmhwm="619044" />
        <model path="intel/action-recognition-0001/action-recognition-0001-encoder/FP32/action-recognition-0001-encoder.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="1151675" vmpeak="1151675" vmrss="276972" vmhwm="276972" />
        <model path="intel/action-recognition-0001/action-recognition-0001-encoder/FP32/action-recognition-0001-encoder.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2433953" vmpeak="2606770" vmrss="368352" vmhwm="619590" />
        <model path="intel/driver-action-recognition-adas-0002/driver-action-recognition-adas-0002-decoder/FP16/driver-action-recognition-adas-0002-decoder.xml" precision="FP16" test="create_exenetwork" device="CPU" vmsize="994177" vmpeak="1046052" vmrss="128486" vmhwm="128486" />
        <model path="intel/driver-action-recognition-adas-0002/driver-action-recognition-adas-0002-decoder/FP16/driver-action-recognition-adas-0002-decoder.xml" precision="FP16" test="create_exenetwork" device="GPU" vmsize="2374886" vmpeak="2458034" vmrss="347391" vmhwm="468119" />
        <model path="intel/driver-action-recognition-adas-0002/driver-action-recognition-adas-0002-decoder/FP16/driver-action-recognition-adas-0002-decoder.xml" precision="FP16" test="inference_with_streams" device="CPU" vmsize="756584" vmpeak="756584" vmrss="170643" vmhwm="170643" />
        <model path="intel/driver-action-recognition-adas-0002/driver-action-recognition-adas-0002-decoder/FP16/driver-action-recognition-adas-0002-decoder.xml" precision="FP16" test="inference_with_streams" device="GPU" vmsize="2476063" vmpeak="2559122" vmrss="349705" vmhwm="468171" />
        <model path="intel/driver-action-recognition-adas-0002/driver-action-recognition-adas-0002-decoder/FP16/driver-action-recognition-adas-0002-decoder.xml" precision="FP16" test="infer_request_inference" device="CPU" vmsize="994172" vmpeak="994172" vmrss="132584" vmhwm="132584" />
        <model path="intel/driver-action-recognition-adas-0002/driver-action-recognition-adas-0002-decoder/FP16/driver-action-recognition-adas-0002-decoder.xml" precision="FP16" test="infer_request_inference" device="GPU" vmsize="2380216" vmpeak="2463271" vmrss="348821" vmhwm="469346" />
        <model path="intel/driver-action-recognition-adas-0002/driver-action-recognition-adas-0002-decoder/FP32/driver-action-recognition-adas-0002-decoder.xml" precision="FP32" test="create_exenetwork" device="CPU" vmsize="990449" vmpeak="990449" vmrss="120738" vmhwm="120738" />
        <model path="intel/driver-action-recognition-adas-0002/driver-action-recognition-adas-0002-decoder/FP32/driver-action-recognition-adas-0002-decoder.xml" precision="FP32" test="create_exenetwork" device="GPU" vmsize="2391407" vmpeak="2492947" vmrss="357682" vmhwm="505237" />
        <model path="intel/driver-action-recognition-adas-0002/driver-action-recognition-adas-0002-decoder/FP32/driver-action-recognition-adas-0002-decoder.xml" precision="FP32" test="inference_with_streams" device="CPU" vmsize="752856" vmpeak="813472" vmrss="162276" vmhwm="162276" />
        <model path="intel/driver-action-recognition-adas-0002/driver-action-recognition-adas-0002-decoder/FP32/driver-action-recognition-adas-0002-decoder.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="2487264" vmpeak="2588804" vmrss="359694" vmhwm="505736" />
        <model path="intel/driver-action-recognition-adas-0002/driver-action-recognition-adas-0002-decoder/FP32/driver-action-recognition-adas-0002-decoder.xml" precision="FP32" test="infer_request_inference" device="CPU" vmsize="995774" vmpeak="1049978" vmrss="123942" vmhwm="123942" />
        <model path="intel/driver-action-recognition-adas-0002/driver-action-recognition-adas-0002-decoder/FP32/driver-action-recognition-adas-0002-decoder.xml" precision="FP32" test="infer_request_inference" device="GPU" vmsize="2391407" vmpeak="2492859" vmrss="363656" vmhwm="511508" />
        <model path="public/faster_rcnn_inception_resnet_v2_atrous_coco/FP32/faster_rcnn_inception_resnet_v2_atrous_coco.xml" precision="FP32" test="inference_with_streams" device="GPU" vmsize="3250161" vmpeak="3491753" vmrss="1119170" vmhwm="1583602" />
    </models>
</attributes>
